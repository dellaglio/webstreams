<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Web Streams Paper</title>
    <link rel="stylesheet" href="https://dokie.li/media/css/lncs.css" media="all" title="LNCS" />
    <link rel="stylesheet alternate" href="https://dokie.li/media/css/acm.css" media="all" title="ACM" />
    <link rel="stylesheet alternate" href="https://www.w3.org/StyleSheets/TR/W3C-ED.css" media="all" title="W3C-ED"/>
    <link rel="stylesheet" href="https://dokie.li/media/css/do.css" media="all" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" media="all" />
    <script src="https://dokie.li/scripts/simplerdf.js"></script>
    <script src="https://dokie.li/scripts/medium-editor.min.js"></script>
    <script src="https://dokie.li/scripts/medium-editor-tables.min.js"></script>
    <script src="https://dokie.li/scripts/do.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/javascript">
      var wrsp="WeSP";

      function load(){
      //Replace variables
      document.getElementsByName('wrsp').forEach(function(entry){
        entry.innerHTML=wrsp;
      })
      var ct=1;

      //References numbering
      $("#references li").each(function(){
        $("[href='#"+this.id+"']").html(ct);
        ct++;
      })

      //Figure numbering
      ct=1;
      $(".fig").each(function(){
        $("[href='#"+this.id+"']").html('Figure '+ct);
        ct++;
      })

      //Listing numbering
      ct=1;
      $(".listing").each(function(){
        $("[href='#"+this.id+"']").html('Listing '+ct);
        ct++;
      })
      //Tables numbering
      ct=1;
      $("table").each(function(){
        $("[href='#"+this.id+"']").html('Table '+ct);
        ct++;
      })

      } 
    </script>
  </head>

  <body about="" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ v: http://www.w3.org/2006/vcard/ns# pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# cal: http://www.w3.org/2002/12/cal/ical# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# org: http://www.w3.org/ns/org# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio#" typeof="schema:CreativeWork sioc:Post prov:Entity" onload="load();">
    <main>
      <article about="" typeof="schema:ScholarlyArticle">
        <h1 property="schema:name">On a Web of Data Streams</h1>

        <div id="authors">
          <dl id="author-name">
            <dt>Authors</dt>
            <dd id="author-1">
              <span about="http://dellaglio.org" rel="schema:creator schema:publisher schema:contributor schema:author">
                <a about="#daniele" typeof="schema:Person" rel="schema:url" property="schema:name" href="http://dellaglio.org">Daniele Dell'Aglio</a>
              </span>
              <span about="#daniele" rel="schema:memberOf" resource="#UZH"></span><sup><a href="#author-org-1">1</a></sup><sup><a href="#author-email-a">a</a></sup>
            </dd>
            <dd id="author-2">
              <span about="" rel="schema:contributor">
                <a about="#Ralf-Gerstner" typeof="schema:Person" rel="schema:url" property="schema:name" href="http://www.springer.com/">Danh Le Phuoc</a>
              </span>
              <span about="#Ralf-Gerstner" rel="schema:memberOf" resource="#Springer-Verlag-Computer-Science-Editorial"></span><sup><a href="#author-org-1">1</a></sup><sup><a href="#author-email-b">b</a></sup>
            </dd>
            <dd id="author-3">
              <span about="" rel="schema:contributor">
                <a about="#Anna-Kramer" typeof="schema:Person" rel="schema:url" property="schema:name" href="http://www.springer.com/">Ali Intizar</a>
              </span>
              <span about="#Anna-Kramer" rel="schema:memberOf" resource="#Springer-Verlag-Computer-Science-Editorial"></span><sup><a href="#author-org-1">1</a></sup><sup><a href="#author-email-c">c</a></sup>
            </dd>
            <dd id="author-4">
              <span about="" rel="schema:creator schema:publisher schema:contributor schema:author">
                <a about="#jpcik" typeof="schema:Person" rel="schema:url" property="schema:name" href="https://w3id.org/people/jpcik/me">Jean-Paul Calbimonte</a>
              </span>
              <span about="#jpcik" rel="schema:memberOf" resource="#HESSO"></span><sup><a href="#author-org-2">2</a></sup><sup><a href="#author-email-d">d</a></sup>
            </dd>
          </dl>

          <ul id="author-org">
            <li id="author-org-1"><sup>1</sup><a about="#UZH" typeof="schema:Organization" property="schema:name" rel="schema:url" href="http://uzh.ch">University of Zurich</a>, <span class="adr"><span class="region">Zurich</span>, <span class="country-name">Switzerland</span></span></li>
            <li id="author-org-1"><sup>1</sup><a about="#Springer-Verlag-Computer-Science-Editorial" typeof="schema:Organization" property="schema:name" rel="schema:url" href="http://www.springer.com/de/">Springer-Verlag, Computer Science Editorial</a>, <span class="adr"><span class="region">Heidelberg</span>, <span class="country-name">Germany</span></span></li>
            <li id="author-org-1"><sup>1</sup><a about="#Springer-Verlag-Computer-Science-Editorial" typeof="schema:Organization" property="schema:name" rel="schema:url" href="http://www.springer.com/de/">Springer-Verlag, Computer Science Editorial</a>, <span class="adr"><span class="region">Heidelberg</span>, <span class="country-name">Germany</span></span></li>
            <li id="author-org-2"><sup>2</sup><a about="#HESSO" typeof="schema:Organization" property="schema:name" rel="schema:url" href="http://www.hevs.ch">University of Applied Sciences and Arts Western Switzerland, HES-SO Valais-Wallis</a>, <span class="adr"><span class="region">Sierre</span>, <span class="country-name">Switzerland</span></span></li>
          </ul>

          <ul id="author-email">
            <li id="author-email-a"><sup>a</sup><a about="#daniele" rel="schema:email" href="mailto:dellaglio@ifi.uzh.ch">dellaglio@ifi.uzh.ch</a></li>
            <li id="author-email-b"><sup>b</sup><a about="#Ralf-Gerstner" rel="schema:email" href="mailto:ralf.gerstner@springer.com">ralf.gerstner@springer.com</a></li>
            <li id="author-email-c"><sup>c</sup><a about="#Anna-Kramer" rel="schema:email" href="mailto:anna.kramer@springer.com">anna.kramer@springer.com</a></li>
            <li id="author-email-d"><sup>d</sup><a about="#jpcik" rel="schema:email" href="mailto:jean-paul.calbimonte@hevs.ch">jean-paul.calbimonte@hevs.ch</a></li>
          </ul>
        </div>

        <div id="content">
          <section id="abstract">
            <h2>Abstract</h2>
            <div datatype="rdf:HTML" property="schema:abstract">
              <p>
               With the growing popularity of IoT and sensor technologies an enormous amount of data 
               is being produced at a very rapid pace.
               Sensor data mostly consists of live data streams containing sensor observations.
               These data streams are generated in a distributed fashion by multiple heterogeneous 
               infrastructures having minimal or no interoperability.
               RDF streams emerged as a model to represent data streams, and RDF Stream Processing (RSP) 
               indicates a set of technologies to process such data.
               Today we can count several successful stories related to RSP research, but we register 
               the fact that in most of the cases the Web dimension is marginal or missing.
               We register the lack of proper infrastructures to enable the exchange of RDF streams 
               over heterogeneous and different types of RDF stream related processors, 
               which features may vary from data generation to querying, from reasoning to visualization.
               In this article, we define a set of requirements related to the creation of a web of 
               RDF stream processors. 
               We then use such requirements to first analyse the current state of the art, and then 
               to build a novel proposal named <span name="wrsp"></span>.
              </p>           
            </div>
          </section>

          <section id="keywords">
            <h2>Keywords</h2>
            <div>
              <ul>
               <li>RDF stream</li>
               <li>RDF stream processing</li>
               <li>Interoperability</li>
               <li>Stream processing</li>
              </ul>
            </div>
          </section>

          <section id="introduction" rel="schema:hasPart" resource="#introduction">
            <h2 property="schema:name">Introduction</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>
               The Web of Data (WoD) vision consists of Web as a distributed database: a vast 
               &mdash;endless&mdash; amount of datasets to be accessed and queried.
               The Linking Open Data (LOD) cloud is one of the most successful examples of such a vision: 
               more than a thousand of datasets, owned and managed by different organizations, exposing 
               interconnected data to be freely accessed.
               The data can be accessed in different ways, and the two most popular solutions are 
               de-referentiation and through SPARQL.
               In the latter case, SPARQL is both a query language for the RDF data exposed in the 
               LOD [<a href="#harris2013"></a>] and a protocol 
               to exchange such data through Internet [<a href="#feigenbaum2013"></a>].
              </p>

              <p>
               Since the late 2000s, we have observed a trend that substantially increased the velocity 
               of part of such data.
               The Internet of Things (IoT) well exemplifies this: sensors create <em>streams</em>, 
               defined as continuous sequences of data generated at very high frequencies, where its 
               value is usually strictly associated to recency, i.e. the quicker the data is processed, 
               the more valuable it is.
               It was therefore normal to ask if the existent WoD solutions were good enough to cope 
               with such data.
               Looking at the research in the database area, it is possible to observe that the typical 
               database approaches show several limits while coping with data streams.
               Stonebraker et al. [<a href="#stonebraker2005"></a>] explains which are the requirements 
               of processing streams, and highlights the limits of DBMS approaches, e.g., their passive 
               processing model badly works with data characterized by extreme velocity; SQL does not 
               support operators to cope with streams; and it is challenging to predict the behaviour 
               of such systems while coping with streaming data.
               It is easy to observe that these limits affect SPARQL and existent WoD solutions.
              </p>

              <p>
               As a possible solution, Stream Processing Engines (SPEs) emerged in the data management 
               research to cope with streaming data.
               They introduce new paradigms and processing models that fit better the requirements of 
               scenarios involving data streams.
               As a result, a new set of languages have been designed and developed, such as CQL, 
               StreamSQL and EPL, with engines and systems designed with the specific task of processing 
               streams.
              </p>

              <p>
               In the Web of Data, these novel paradigms inspired RDF Stream Processing (RSP): it builds 
               on top of SPEs to mitigate the data heterogeneity issues by exploiting semantic web 
               technologies.
               As the name suggests, such systems are designed process data streams modelled through RDF, 
               and they offer a wide set of operators, from typical SPE operations (e.g., filters, 
               aggregations, event pattern matching) to reasoning processes.
              </p>

              <table id="tab:overview">
                <caption>Comparison between data management and web of data paradigms</caption>
                <thead>
                  <tr>
                    <th></th><th>DB</th><th>SPE</th><th>WoD</th><th>WoDS</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Processing</td>
                    <td>SQL</td>
                    <td>StreamSQL (et al.)</td>
                    <td>SPAR<b>QL</b></td>
                    <td>RSP-QL (et al.)</td>
                  </tr>
                  <tr>
                    <td>Data exchange</td>
                    <td>-</td>
                    <td>-</td>
                    <td>HTTP, S<b>P</b>ARQL</td>
                    <td>?</td>
                  </tr>
                </tbody>
              </table>

              <p>
               RSP fills an important gap between the Web of Data towards a Web of Data Streams (WoDS): 
               it introduces processing models and languages to process streams on the Web, mostly of 
               them captured by reference models as RSEP-QL \cite{} and LARS \cite{}.
               However, an important elements is still missing, and it is a technical infrastructure 
               to manage data exchange.
               As depicted in <a href="#tab:overview"></a>, data can be exchanged by HTTP (following 
               the linked data principles) or via the SPARQL protocol.
               These solutions perfectly suit the cases where engines follow passive processing models, 
               i.e., they pull the data when needed, but not when engines adopt passive processing models.
              </p>

              <p>
               In this paper, we ask <em>what is the best data exchange infrastructure to perform 
               stream processing on the Web?</em> \dd{what is a ( suitable [or] proper ) data exchange 
               infrastructure to perform stream processing on the Web?}\jpc{tricky: is it only an 
               infrastructure what we propose? }
               In other words, we ask ourselves how can we build an infrastructure that enables the 
               scenario in <a href="#fig:overview">Figure</a>: a network of RSP engines, distributed on 
               the Web, able to exchange and process RDF streams among them.
              </p>

              <figure id="fig:overview" class="fig">
                <object data="img/overview.png"  type="image/png" width="200"></object>
                <figcaption>Overview</figcaption>
              </figure>

              <p>
               The solution should take into account the nature of the streams and the engines, as 
               well as the Web setting.
               We should indeed consider that existing RSP engines are heterogeneous in terms of operators 
               and APIs to control them, as well as the nature of the Web, that is distributed and relies 
               on existing technologies and standards.
               We envision a scenario as the one depicted in <a href="#fig:overview">Figure</a>: 
               interconnected RSPs that perform several tasks such as querying to reasoning, exchanging the 
               results and producing sophisticated analyses.
              </p>

              <p>
               In the following we present <span name="wrsp"></span>, a framework to build complex network 
               of RSP engines on the Web.
               <span name="wrsp"></span> brings a communication protocol to initialize the connection between 
               two RSP engines and to manage the data exchange.
               This is implemented through two interfaces for the elements that produce and consume streams, 
               and a vocabulary to annotate a stream.
               We design and build <span name="wrsp"></span> taking into account existing previous results 
               such as the W3C RSP-CG reports \cite{}, existing RSP engines, protocol and standards.
               We empirically show that <span name="wrsp"></span> enables the construction of a Web of Data 
               Streams by evaluating the introduced overhead and making a study about scalability.
              </p>

              <p>
               The paper is structured as follows.
               We set requirements for communication of Web stream processors in 
               Section <a href="#reqs">2</a>.
               In Section <a href="#related-work">3</a>, we review the state of the art and we discuss 
               the solutions available so far.
               Section <a href="#rsep">6</a> presents <span name="wrsp"></span>, describing its components 
               and presenting some existing implementation.
               We evaluate <span name="wrsp"></span> in Section <a href="#impl">5</a> before concluding with 
               remarks and future directions in Section <a href="#concl">6</a>.
              </p>
            </div>
          </section>

          <section id="reqs" rel="schema:hasPart" resource="#reqs">
            <h2 property="schema:name">Requirements</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>
               To design an infrastructure to exchange RDF streams on the Web, we first define a set 
               of requirements.
               As we will see, three of them are extensions of Stonebraker et al.'s rules for 
               SPE [<a href="#stonebraker2005"></a>], while others are elicited from real-world 
               <a href="https://www.w3.org/community/rsp/wiki/Use_cases">use cases</a>.
              </p>
              <br>
              <section id="sec:scenario-req-1">
                <h4 property="schema:name">R1: Keep the data moving</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   The first rule of [<a href="#stonebraker2005"></a>] states that a SPE "should use an 
                   active (i.e., non-polling) processing model".
                   Looking at the WoD, we can notice that most of the interactions follow a polling paradigm 
                   and are stateless.
                   This is a direct consequence of the client-server paradigm at the basis of HTTP and the 
                   Web: servers supplying resources to client on demand.
                   In this sense, the WoD is not the most suitable environment to perform stream	processing.
                   Therefore, as first requirement, <em><span name="wrsp"></span> must prioritize active 
                   paradigms for data stream exchange, where the data supplier can <em>push</em> the stream 
                   content to the actors interested in it</em>.
                  </p>
                </div>
              </section>
              <br>
              <section id="sec:scenario-req-2">
                <h4 property="schema:name">R2: Stored and streamed data</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   The fifth rule of [<a href="#stonebraker2005"></a>] is about the "capability to 
                   efficiently store, access and modify state information, and combine it with live 
                   streaming data".
                   We need to revisit this rule by a WoD point of view, in particular about the notion 
                   of stored data.
                   In our context, this data is represented by any dataset that is exposed to the Web 
                   through SPARQL endpoints or through Linked Data technologies.
                   Our second requirement states that <em><span name="wrsp"></span> must enable the 
                   combination of streaming and stored data</em>.
                   In this case combination has a broad meaning, and may refer to several operations, 
                   such as stream enrichment, stream storage or fact derivation.
                  </p>
                </div>
              </section>
              <br>
              <section id="sec:scenario-req-3">
                <h4 property="schema:name">R3: High availability, distribution and scalability</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   The sixth rule of [<a href="#stonebraker2005"></a>] states that  "ensure that the 
                   applications are up and available, and the integrity of the data maintained at all 
                   times, despite failures", while the seventh states that SPE "must be able to distribute 
                   its processing across multiple processors and machines to achieve incremental scalability. 
                   Ideally, the distribution should be automatic and transparent".
                   Even if such rules are mainly related to the stream processing engine architectures, 
                   we can infer some useful indication for the design of <span name="wrsp"></span>.
                   Our third requirement is that <em><span name="wrsp"></span> must enable the possibility 
                   to build reliable, distributed and scalable streaming applications</em>.
                  </p>
                </div>
              </section>
              <br>
              <section id="sec:scenario-req-4">
                <h4 property="schema:name">R4: Operations on the stream content</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   Every use case has special requirements on the way the streaming data should processed.
                   Querying is an option when the goal is to aggregate, filter and look of relevant 
                   pattern of events.
                   However, other alternatives are possible, such as deductive, inductive and other types 
                   of reasoning; stream generation and visualization.
                   <em><span name="wrsp"></span> must guarantee a wide range of operations over the stream</em>.
                   Such a requirement is important, in particular on the Web perspective, where data may 
                   be accessed and used in unexpected ways by third-part entities.
                   \jpc{wide range of operations: is it too vague?}
                  </p>
                </div>
              </section>
              <br>
              <section id="sec:scenario-req-5">
                <h4 property="schema:name">R5: Accessible information about the stream</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   While the nature of the stream content is highly dynamic and volatile, the stream 
                   itself is a resource that can be described.
                   Such descriptions are needed in a number of cases.
                   For example, statistics about the frequency and the size of the stream content may be 
                   used to enable query optimization in the RSP engines; information about the generation 
                   of the stream may be used to enable provenance-related reasoning; description of the 
                   features of the streams may be collected in registries to achieve search and discovery.
                   Our fifth requirement states that <em><span name="wrsp"></span> must support the 
                   publication of stream descriptions</em>.
                  </p>
                </div>
              </section>
              <br>
              <section id="sec:scenario-req-6">
                <h4 property="schema:name">R6: Stream variety support</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   The descentralized and bottom-up nature of the Web make hard &mdash;if not impossible&mdash; 
                   to define \emph{the} model and serialization format for streams.
                   Looking at the use cases in the RSP-CG wiki, it is easy to observe that: streams can have 
                   different velocities (e.g., one new item every minute vs every millisecond); time annotations 
                   can be composed by zero, one, two or more time instants, item schemata can be simple (e.g., 
                   numbers) or complex (e.g., graphs or tables).
                   To preserve the heterogeneity that characterize the Web, <em><span name="wrsp"></span> should 
                   support the exchange of a wide variety of streams</em>.
                  </p>
                </div>
              </section>
              <br>
              <section id="sec:scenario-req-7">
                <h4 property="schema:name">R7: Reuse of technologies and standards</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   A common problem when building new frameworks and infrastructures is to find a good 
                   trade-off among what is new and what exists.
                   On the one hand, creating everything from scratch is an opportunity to create a solution 
                   that perfectly fits the requirements, but on the other hand adopting existing specifications 
                   (i.e., standards and protocols) allows reusing existing tools and methods.
                   This is particular true on the Web, where guaranteeing compatibility is mandatory in order 
                   to enable interoperability.
                   Our last requirements states that the design of <em><span name="wrsp"></span> should exploit 
                   as much as possible existing protocols and standards</em>.
                  </p>
                </div>
              </section>
            </div>
          </section>

          <section id="related-work" rel="schema:hasPart" resource="#related-work">
            <h2 property="schema:name">Related Work</h2>
                       <ul>
                        <li>RSP CG Abstract syntax</li>
                        <li>serialization</li>
                        <li>RSP services</li>
                        <li>LDN</li>
                      </ul>

\item usual citations to RSP engines
\item SPARQLpush, LDN etc
%our contribution

\item Something on Web Services?
\item protocols: MQTT, WebSocket, HTTP, etc.
\item the Abstract syntax of W3C RSP - our work is compliant to that model (probably)
\item TripleWave

\twave\footnote{\twave: \url{http://streamreasoning.github.io/TripleWave/}}, is an open-source framework for creating RDF streams and publishing them over the Web.
Triplewave facilitates the dissemination and consumption of RDF streams, in a similar manner as is already common for static RDF datasets with RDF graphs and datasets.

\item ontologies
\begin{itemize}
\item IoT ontologies: SSN, the one of Monika, etc.
\item SPARQL federation ontologies
\end{itemize}
\end{itemize}

RSP engines emerged in recent years, with the goal of extending RDF and SPARQL to process RDF streams.
%
They can be broadly divided into two groups.

RSPs influenced by CEP reactively process the input streams to identify relevant events and sequences of them. 
EP-SPARQL~\cite{Anicic2011} is one of the first RSP that adopts some of these complex pattern operators. 

Other such recent approaches include Sparkwave~\cite{Komazec2012} and Instans~\cite{Rinne2012}. 
%
On the other hand, approaches inspired by DSMS exploit sliding window mechanisms to capture a recent and finite portion of the
input data, enabling their processing through SPARQL operators in an atemporal fashion.
%
C-SPARQL~\cite{Barbieri2010}, CQELS~\cite{lephuoc2011native}, and SPARQLStream~\cite{calbimonte2012} are representative 
examples of this group. % of RSP engines.

Other approaches have proposed to create RDF datasets fed from unstructured streams~\cite{gerber2013,trinh2014web}, to lift 
streaming data as Linked Data~\cite{balduini2013,lephuoc2012}, or to provide virtual RDF Streams~\cite{calbimonte2012}. 
To improve scalability, systems like Ztreamy~\cite{fisteus2014ztreamy} are designed for efficient transmission of compressed data 
streams, although they do not address the heterogeneity of data sources, declarative transformation and consumption modes.

          </section>

          <section id="rsep" rel="schema:hasPart" resource="#rsep">
            <h2 property="schema:name">A framework to exchange RDF streams on the Web</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <section id="rdf-stream" rel="schema:hasPart" resource="#rdf-stream">
               <h3 property="schema:name">RDF stream: model and serialization</h3>
               <div datatype="rdf:HTML" property="schema:description">
                 <p>
                   Following the requirements and the type of scenarios that we address in this work, we 
                   need to represent heterogeneous data streams, which can be shared by different processing 
                   engines, and whose data can be not only retrievable but interpretable and distributable among 
                   these engines.
                   The RDF model lends itself as a natural candidate for representing different types of data, 
                   thanks to its flexibility in data modeling, and the usage of well established standards, designed 
                   for the Web.
                   However, in order to be used in a streaming scenario, the RDF model needs extensions, 
                   as shown in previous works [<a href="#lephuoc2011"></a>,<a href="#barbieri2010"></a>].
                 </p>

                 <p>
                   We can distinguish two kinds of data in the requirements, first the streaming data, 
                   which are by nature highly dynamic and labeled with time annotations.
                   Second, the contextual or background data, which changes lees often, provides information that 
                   enriches the streaming data (e.g. including location, profiles, producer data, system 
                   descriptions, etc.).
                   For the latter, RDF graphs can be used as an underlying data model, while streams can be 
                   captured using an extended RDF stream data model.
                 </p>

                 <p>
                   To fulfil these goals, we adopt the notion of time-annotated RDF graphs as elements 
                   of RDF streams, following the data model under design by the 
                   <a href="https://www.w3.org/community/rsp/">W3C RSP Community Group</a> (RSP CG).
                 </p>

                 <p>
                   We define a <em>timeline</em> \(T\) as an infinite, ordered sequence of time entities 
                   \((t_1, t_2,\ldots)\), where \(t_i{\in}\mbox{ TimeEntities}\)
                   and for all \(i{>}0\), it holds that \(t_{i}\) happened before \(t_{i+1}\). When the time 
                   entities are restricted to instants, \(t_{i+1}-t_i\) is a constant, 
                   i.e. the <em>time unit</em> of \(T\).
                 </p>

                 <p>
                   Following the definitions in [<a href="#dellaglio2016"></a>], the definition of RDF streams 
                   can be formulated as an extension of RDF Graphs with time annotations.
                 </p>
             
                 <br>
                 
                 <h4>RDF Stream</h4>
                 <p>
                   A <em>timestamped RDF graph</em> is a pair \((G, t)\), where \(G\) is an RDF graph and 
                   \(t\in T\) is a time entity.  An <em>RDF stream</em> \(S\) is a (potentially) unbounded 
                   sequence of timestamped RDF graphs in a non-decreasing time order:

                   <figure class="equation" typeof="doco:FormulaBox">
                     $$S=(G_1,t_1),(G_2,t_2),(G_3,t_3),(G_4,t_4),\ldots$$
<!-- this is hell      
                     <math xmlns="http://www.w3.org/1998/Math/MathML">
                       <mi>S</mi><mo>=</mo>
                       <mo>(</mo><msub><mi>G</mi><mn>1</mn></msub><mo>,</mo><msub><mi>t</mi><mn>1</mn></msub><mo>)</mo><mo>,</mo>
                       <mo>(</mo><msub><mi>G</mi><mn>2</mn></msub><mo>,</mo><msub><mi>t</mi><mn>2</mn></msub><mo>)</mo><mo>,</mo>
                       <mo>(</mo><msub><mi>G</mi><mn>3</mn></msub><mo>,</mo><msub><mi>t</mi><mn>3</mn></msub><mo>)</mo><mo>,</mo>
                       <mo>(</mo><msub><mi>G</mi><mn>4</mn></msub><mo>,</mo><msub><mi>t</mi><mn>4</mn></msub><mo>)</mo><mo>,</mo>
                       <mo>&#x2026;</mo>
                     </math>
-->
                   </figure>

                   where, for every \(i>0\), \((G_i,t_i)\) is a timestamped RDF graph and \(t_i \leq t_{i+1}\).
                 </p>

                 <p>
                   In this work, we focus on the model where the time annotation is
                   represented by one time instant, as it is a usual case that appears in relevant scenarios.
                   As an example, consider the following stream \(S\):
                     $$S{=}(G_1,2),(G_2,4),(G_3,6),(G_4,8),(G_5,10),\ldots$$,
                   where each \(G_i\) contains the depicted RDF triples in <a href="#fig:streamexample"></a>.
                 </p>

                 <figure id="fig:streamexample" class="fig">
                   <object data="img/streamexample.png"  type="image/png" style="min-height:0px;"></object>
                   <figcaption>Overview</figcaption>
                 </figure>   


                 <figure class="listing">
                   <pre>
<code>{"http://www.w3.org/ns/prov#generatedAtTime": "2015-06-30T16:44:59.587Z",</code>
<code> "@id": "http://streamreasoning.org/TripleWave/ak10992887",</code>
<code> "@graph": [</code>
<code>  { "@id": "http://streamreasoning.org/TripleWavee/ak10992887",</code>
<code>    "@type": "cbench:TrafficObservation",</code>
<code>    "ssn:observedProperty": "cbench:TrafficData",</code>
<code>    "ssn:hasValue": "32",</code>
<code>    "ssn:observedBy": "ins-event:AarhusTrafficData158505"</code>
<code>  }],</code>
<code> "@context": {</code>
<code>    "ssn": "http://www.w3.org/2002/12/cal/ical#",</code>
<code>    "cbench": "http://www.w3.org/2001/XMLSchema#",</code>
<code>    "ins-event": "http://www.insight-centre.org/dataset/SampleEventService#"</code>
<code>}</code>
                   </pre>
                   <figcaption>Some caption, what is this example?</figcaption>
                 </figure>
               </div>
             </section>

              <section id="protocol" rel="schema:hasPart" resource="#protocol">
               <h3 property="schema:name">Communication protocol</h4>
               <div datatype="rdf:HTML" property="schema:description">
                 <p>
                   We identify two interfaces, namely <em>producer</em> and <em>consumer</em>.
                   As the names suggest, the former is implemented by actors that distribute streams 
                   across the Web, while the latter is implemented actors who wants to receive streams.
                 </p>

                 <p>
                   Every actor involved in the processing may implement either interface, as well as both 
                   of them. This lead us to the following nomenclature.
                   A <em>stream source</em> implements the producer interface only. Services exposing sensors 
                   data on the Web and TripleWave are examples of stream sources.
                   Similarly, a <em>stream sink</em> implements the consumer interface only, e.g. a dashboard 
                   visualising information for the final user.
                   Finally, a <em>stream transformer</em> implements both the interfaces: it gets as input a 
                   stream and outputs another stream, e.g. a stream processor or a stream reasoner.
                 </p>

                 <p>
                   The principal responsibility of the producers is to make streaming data accessible. It is 
                   done by exposing <em>Stream Descriptors</em>, i.e. metadata about the streams.
                   Examples of Stream Descriptor contents are the creator, the adopted vocabulary and statistical 
                   information about the stream.
                   However, the most relevant data the Stream Descriptor brings is about how to effectively access 
                   the stream content.
                   We detail the stream descriptor in Section <href a="#service-descriptor"></a>; in the following, 
                   we describe how the producer/consumer communication develops.
                 </p>

                 <figure id="fig:protocol" class="fig">
                   <object data="img/consume.png"  type="image/png" width="200"></object>
                   <figcaption>Protocol to establish the communication between the producer and the consumer 
                   interfaces</figcaption>
                 </figure>

                 <p>
                   The communication relies on two phases, depicted in <a href="#fig:protocol">Figure</a>, and it 
                   starts on the consumer side.
                   The consumer only needs to be aware of the IRI of the Stream Descriptor, e.g. consumer user 
                   provides it as instruction.
                   This is what is needed for the first phase, where the consumer accesses the Stream Descriptor 
                   IRI (the blue part in <a href="#fig:protocol">Figure</a>) through a HTTP request, following the 
                   Linked Data principles.
                 </p>

                 <p>
                   In the second phase, the consumer starts to receive the stream (the light blue part in 
                   <a href="#fig:protocol">Figure</a>).
                   The Service Descriptor brings information about how to access the effective stream content.
                   That means it describes one or more ways to establish the connection between the consumer and 
                   the endpoint that is providing the stream content.
                   This connection can happen with different protocols, based on push mechanisms. e.g. WebSocket and 
                   MQTT, as well as based on pull mechanisms, e.g. HTTP.
                   Among the several options offered by the producer through the Service Descriptor, consumers chose 
                   the way they prefer.
                   After the decision, consumer can start to receive the stream content and to process it.
                 </p>

                 <p>
                   The choice to allow several channels to distribute the streams gives the freedom to adopt several 
                   channels to exchange the streams, relying on different technologies based on requirements in the 
                   scenario.
                 </p>
               </div>
             </section>

              <section id="service-descriptor" rel="schema:hasPart" resource="#service-descriptor">
               <h3 property="schema:name">Service Descriptor</h3>
               <div datatype="rdf:HTML" property="schema:description">
                 <p>
                   The Stream Descriptor is an RDF document providing metadata of the RDF stream that is used by a 
                   <em>consumer</em> for bootstrapping its stream consuming process.
                   Realizing that RDF Stream is also an RDF dataset, we extend 
                   <a  href="https://www.w3.org/TR/vocab-dcat/">DCAT vocabulary</a> to represent the an RDF Stream as 
                   illustrated in <a href="#fig:schema">Figure</a>.
                   The class RDFStream extends dcat:DataSet to inherit all properties of a RDF dataset, and it also 
                   has the properties specific to a stream such as <em>streamrate</em> and <em>streamTemplate</em>.
                   The <em>streamTemplate</em> property can be used to point to a document that specify the template 
                   or the constraint of the RDF stream, for instance, the template can be a RDF document driven 
                   <a href="https://www.w3.org/TR/shacl/">SHACL</a>.
                   The template can be used as a hint of the data shape of the RDF stream for the consumer to optimize 
                   its processing.
                   It also plays the role as a validation rule for consumer to verify if the incoming data is conformed 
                   with the template.
                 </p>

                 <figure id="fig:schema" class="fig">
                   <object data="img/streamschema.png"  type="image/png" width="200"></object>
                   <figcaption>Description of RDF Stream</figcaption>                 
                 </figure>

                 <figure class="listing">
                   <pre>
<code>{"@context": {</code>
<code>  "sld": "http://streamreasoning.org/ontologies/wsd#",</code>
<code>  "generatedAt": { </code>
<code>   "@id": "http://www.w3.org/ns/prov#generatedAtTime",</code>
<code>   "@type": "http://www.w3.org/2001/XMLSchema#dateTime" </code>
<code>  }</code>
<code> },</code>
<code> "@type": "wsd:RDFStream",</code>
<code> "dcat:accessURL": "ws://localhost:8101/TripleWave/replay",</code>
<code> "wsd:streamTemplate": {"@id":"http://purl.oclc.org/NET/ssnx/ssn"},</code>
<code> "wsd:shacl": {</code>
<code>  "@list": [</code>
<code>   { "generatedAt": "2016-04-21T13:01:18.663Z", "@id": "tr:1461243678663" },</code>
<code>   { "generatedAt": "2016-04-21T13:01:19.784Z", "@id": "tr:1461243679784" }</code>
<code>  ]</code>
<code> },</code>
<code> "sld:lastUpdated": "2016-04-21T13:02:06.575Z"</code>
<code>}</code>
                   </pre>
                   <figcaption>The Stream Descriptor pointing to the iGraph described in Listing~\ref{list:datastreamjson}.</figcaption>
                 </figure>

                 <p>
                   Note that an RDF can be distributed via different stream channels using different protocols 
                   like MQTT and Websocket.
                   Therefore, a stream channel is an instance of the RDFStreamPublisher class which is linked 
                   to the RDFStream class via the property <em>dcat:distribution</em>.
                   The RDFStreamPublisher is used to specify the protocol and the URL whereby the consumer can 
                   tap into to receive the stream.
                   Also, RDFStreamPublisher is a subclass of the dcat:Distribution class which has several 
                   properties for the consumer to configure its parsers such as <em>dcat:mediaType</em> and 
                   <em>dcat:format</em>.
                   An RDFStreamPublisher might provide a continuous query service which is specified by the 
                   RSPService class extended from the sd:Service defined by 
                   <a href="https://www.w3.org/TR/sparql11-service-description/">SPARQL 1.1 Service description</a>.
                   As most of RSP engines extend SPARQL 1.1 for their query languages, using the federated service 
                   vocabularies will provide useful vocabularies for describing RDF continuous querying services 
                   powered by RSP engines such as C-SPARQL and CQELS.
                 </p>
               </div>
             </section>
            </div>
          </section>

          <section id="impl" rel="schema:hasPart" resource="#impl">
            <h2 property="schema:name">Implementation and examples</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <section id="impl" rel="schema:hasPart" resource="#impl">
                <h3 property="schema:name">Stream source example: TripleWave</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   TripleWave [<a href="#mauri2016"></a>] is a framework to create and expose RDF streams 
                   according to the producer interface described above.
                   Triplewave can be fed with different input, such as non-RDF Web streams or RDF data 
                   containing some temporal annotation.
                  </p>

                  <p>
                   In the former case, TripleWave lifts existing Web streams in RDF streams, such as the 
                   <a href="https://en.wikipedia.org/wiki/Special:RecentChanges">Wikipedia update stream</a> 
                   and <a href="https://dev.twitter.com/streaming/overview">Twitter stream</a>.
                   The operation is enabled through R2RML transformations [<a href="#das2012"></a>], that map 
                   relational to RDF data.
                   The lifting operation enables the interoperability among the WSP actors, addressing \dd{Rx}.
                  </p>

                  <p>
                   In the latter case, TripleWave streams out data stored in a repository.
                   This mode is useful for benchmarking as well as experimental runs, where data has to be 
                   streamed multiple times across the overall network.
                   Precondition to this mode is the existence of time information associated to the repository 
                   content: TripleWave uses them to compute the correct intervals between consecutive events and 
                   set delays accordingly.
                  </p>

                  <p>
                   TripleWave has been designed and implemented to natively implement the producer interface. 
                   It exposes the Service Descriptor on an HTTP address, and publishes the streaming data through 
                   MQTT and WebSocket.
                  </p>
                </div>
              </section>

              <section id="impl" rel="schema:hasPart" resource="#impl">
                <h3 property="schema:name">Stream transformer example: C-SPARQL and CQELS</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   It is possible to create WSP actors out of existing stream processors by introducing adapters.
                   We depict this possibility by presenting the cases of C-SPARQL [<a href="#barbieri2010"></a>] 
                   and CQELS [<a href="#lephuoc2011"></a>], two RDF Stream Processing (RSP) engines, i.e. stream 
                   processing engines supporting query languages for graph processing, usually extensions of 
                   SPARQL [<a href="#harris2013"></a>].
                  </p>

                  <p>
                    These engines offers APIs to manage the communication, i.e. (i) declare RDF streams, (ii) push 
                    the stream items into the declared RDF Streams, (iii) register the query, (iv) register listeners 
                    to obtain query results.
                    The WSP-RSP adapter should implement the producer and consumer interfaces according to such APIs.
                  </p>

                  <p>
                    The implementation of the consumer interface in the adapter should enable the connection to a 
                    stream source or transformer, according to the protocol described above.
                    Given the nature of such engines, the control of the engine should happen in a query-driven way.
                    That means, when a new query is registered, the engine should establish the connections for the 
                    streams needed to evaluate the query.
                    The main problem is related to the discovery of the streams: how to let the engine know where 
                    the streams are?
                    The solution we propose is based on the following consideration: both the languages adopted by 
                    the engines (respectively C-SPARQL and CQELS-QL) offer the possibility to declare the stream 
                    through a IRI, as shown in Listing~\ref{lst:query1}. \dd{fill with the example}
                    If such IRI denotes a Stream Descriptor address, engines would have the information they need to 
                    establish the connection.
                  </p>

                  <p>
                    Similarly to the consumption, the stream production is query driven. RSP engines stream out the 
                    query results and make it available to other agents (e.g. users, other engines, etc.).
                    The WSP-RSP adapter implements the producer interface as follows. For each query that is registered 
                    in the engine, the adapter performs two actions.
                    First, it creates a Stream Descriptor and exposes it at an HTTP address.
                    Second, it registers a listener to manage the answers.
                    The current implementation provides the listeners for MQTT and WebSocket.
                    The first forwards the results to an MQTT channel, while the latter sends the result to the adapter, 
                    that manages the ongoing connections.
                    In this way, several actors may access the results of the same query.
                  </p>
                </div>
              </section>
            </div>
          </section>

          <section id="concl" rel="schema:hasPart" resource="#concl">
            <h2 property="schema:name">Conclusions</h2>
            <div datatype="rdf:HTML" property="schema:description">
            </div>
          </section>


          <section id="references">
            <h2>References</h2>
            <div>
             <ol>
                <li id="anicic2011" property="schema:citation"> 
                  D. Anicic, P. Fodor, S. Rudolph, and N. Stojanovic. 
                  EP-SPARQL: a unified language for event processing and stream reasoning. 
                  In WWW, pages 635-644, 2011.</li>
                <li id="balduini2013" property="schema:citation">
                  M. Balduini, E. Della Valle, D. Dell'Aglio, M. Tsytsarau, T. Palpanas, and C. Confalonieri.
                  Social Listening of City Scale Events Using the Streaming Linked Data Framework. 
                  In International Semantic Web Conference (2), volume 8219 of Lecture Notes in Computer Science, pages 1-16. Springer, 2013.</li>
                <li id="barbieri2010" property="schema:citation">
                  D. F. Barbieri, D. Braga, S. Ceri, E. Della Valle, and M. Grossniklaus. 
                  C-SPARQL: a Continuous Query Language for RDF Data Streams. 
                  Int. J. Semantic Computing, 4(1):3{25, 2010.</li>
                <li id="barbieri2010a" property="schema:citation">
                  D. F. Barbieri and E. Della Valle. 
                  A proposal for publishing data streams as linked data - A position paper. 
                  In LDOW, 2010.</li>
                <li id="calbimonte2012" property="schema:citation">
                  J.-P. Calbimonte, H. Jeung, O. Corcho, and K. Aberer. 
                  Enabling query technologies for the semantic sensor web. 
                  Int. J. Semantic Web Inf. Syst., 8:43{63, 2012.
                <li id="das2012" property="schema:citation">
                  S. Das, S. Sundara, and R. Cyganiak. R2rml: RDB to RDF Mapping Language.
                  W3C Recommendation, W3C, 2012.</li>
                <li id="dellaglio2016" property="schema:citation">
                  D. Dell'Aglio, M. Dao-Tran, J.-P. Calbimonte, D. L. Phuoc, and E. Della Valle.  
                  A Query Model to Capture Event Pattern Matching in RDF Stream Processing Query Languages. 
                  In EKAW, volume 10024 of Lecture Notes in Computer Science, pages 145-162, 2016.</li>
                <li id="feigenbaum2013" property="schema:citation">
                  L. Feigenbaum, G. T. Williams, K. G. Clark, and E. Torres. 
                  SPARQL 1.1 Protocol.
                  W3C Recommendation, W3C, 2013.</li>
                <li id="fisteus2014" property="schema:citation">
                  J. A. Fisteus, N. F. Garcia, L. S. Fernandez, and D. Fuentes-Lorenzo. 
                  Ztreamy: A middleware for publishing semantic streams on the web. 
                  J. Web Semantics, 25:16-23, 2014.</li>
                <li id="gerber2013" property="schema:citation">
                  D. Gerber, S. Hellmann, L. Buhmann, T. Soru, R. Usbeck, and A.-C. N. Ngomo.
                  Real-time rdf extraction from unstructured data streams. 
                  In ISWC, pages 135-150. 2013.</li>
                <li id="harris2013" property="schema:citation">
                  S. Harris and A. Seaborne. 
                  SPARQL 1.1 Query Language. W3c Recommendation, W3C, 2013.
                <li id="komazec2012" property="schema:citation">
                  S. Komazec, D. Cerri, and D. Fensel. 
                  Sparkwave: continuous schema-enhanced pattern matching over RDF data streams. 
                  In DEBS, pages 58-68. 2012.</li>
                <li id="lephuoc2011" property="schema:citation">
                  D. Le Phuoc, M. Dao-Tran, J. X. Parreira, and M. Hauswirth. 
                  A Native and Adaptive Approach for Unified Processing of Linked Streams and Linked Data.
                  In International Semantic Web Conference (1), volume 7031 of Lecture Notes in Computer Science, pages 370-388. Springer, 2011.</li>
                <li id="lephuoc2012" property="schema:citation">
                  D. Le-Phuoc, H. Q. Nguyen-Mau, J. X. Parreira, and M. Hauswirth. 
                  A middleware framework for scalable management of linked streams. 
                  J. Web Semantics, 16:42-51, 2012.</li>
                <li id="mauri2016" property="schema:citation">
                  A. Mauri, J.-P. Calbimonte, D. Dell'Aglio, M. Balduini, M. Brambilla, E. D. Valle, and K. Aberer. 
                  TripleWave: Spreading RDF Streams on the Web. 
                  In International Semantic Web Conference (2), volume 9982 of Lecture Notes in Computer Science, pages 140-149, 2016.</li>
                <li id="rinne2012" property="schema:citation">
                  M. Rinne, S. Torma, and E. Nuutila. 
                  SPARQL-based applications for RDF encoded sensor data. 
                  In SSN, volume 904, pages 81-96. 2012.</li>
                <li id="schmidt2011" property="schema:citation">
                  M. Schmidt, O. Gorlitz, P. Haase, G. Ladwig, A. Schwarte, and T. Tran. 
                  Fedbench: A benchmark suite for federated semantic data query processing. 
                  In The Semantic Web - ISWC 2011 - 10th International Semantic Web Conference, Bonn, Germany, October 23-27, 2011, Proceedings, Part I, volume 7031 of Lecture Notes in Computer Science, pages 585-600. Springer, 2011.</li>
                <li id="schwarte2011" property="schema:citation">
                  A. Schwarte, P. Haase, K. Hose, R. Schenkel, and M. Schmidt. 
                  Fedx: A federation layer for distributed query processing on linked open data.
                  In The Semanic Web: Research and Applications - 8th Extended Semantic Web Conference, ESWC 2011, Heraklion, Crete, Greece, May 29 - June 2, 2011, Proceedings, Part II, volume 6644 of Lecture Notes in Computer Science, pages 481-486. Springer, 2011.</li>
                <li id="stonebraker2005" property="schema:citation">
                  M. Stonebraker, U. Cetintemel, and S. B. Zdonik. 
                  The 8 requirements of real-time stream processing. SIGMOD Record, 34(4):42{47, 2005.</li>
                <li id="trinh2014" property="schema:citation">
                  T.-D. Trinh, P. Wetz, B.-L. Do, A. Anjomshoaa, E. Kiesling, and A. M. Tjoa.
                  A web-based platform for dynamic integration of heterogeneous data. 
                  In IIWAS, pages 253-261, 2014.</li>
             </ol>
                        </div>
          </section>
        </div>
      </article>
    </main>
  </body>
</html>
