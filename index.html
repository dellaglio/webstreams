<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>On a Web of Data Streams</title>
    <link href="https://dokie.li/media/css/lncs.css" media="all" rel="stylesheet" title="LNCS" />
    <link href="https://dokie.li/media/css/acm.css" media="all" rel="stylesheet alternate" title="ACM" />
    <link href="https://www.w3.org/StyleSheets/TR/W3C-ED.css" media="all" rel="stylesheet alternate" title="W3C-ED" />
    <link href="https://dokie.li/media/css/do.css" media="all" rel="stylesheet" />
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" media="all" rel="stylesheet" />
    <script src="https://dokie.li/scripts/simplerdf.js"></script>
    <script src="https://dokie.li/scripts/medium-editor.min.js"></script>
    <script src="https://dokie.li/scripts/do.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script async="true" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/javascript">
      //<![CDATA[
      var wrsp="WeSP";

      function load(){
      //Replace variables
      $("[name='wrsp']").each(function(){
        $(this).html(wrsp);
      })
      var ct=1;

      //References numbering
      $("#references li").each(function(){
        $("[href='#"+this.id+"']").html(ct);
        ct++;
      })

      //section numbering
      ct=1;
      $("section > h2").each(function(){
        var id=$(this).parent().attr('id')
        if (id!='keywords' && id!='abstract') {
          console.log(id+' '+ct)
          $("[href='#"+id+"']").html('Section '+ct);
          ct++;
        }
      })

      //Figure numbering
      ct=1;
      $(".fig").each(function(){
        $("[href='#"+this.id+"']").html('Figure '+ct);
        ct++;
      })

      //Listing numbering
      ct=1;
      $(".listing").each(function(){
        $("[href='#"+this.id+"']").html('Listing '+ct);
        ct++;
      })
      //Tables numbering
      ct=1;
      $("table").each(function(){
        $("[href='#"+this.id+"']").html('Table '+ct);
        ct++;
      })

      }
    //]]>
    </script>
    <style>
      @media print {
        a {
          text-decoration: underline !important;
          color: rgb(0, 0, 238) !important;
        }
      }
        #authors li {
            white-space: nowrap;
        }  
        h4 {
            display: inline-table;
        }
    </style>
  </head>

  <body about="" onload="load();" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ v: http://www.w3.org/2006/vcard/ns# pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# cal: http://www.w3.org/2002/12/cal/ical# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# org: http://www.w3.org/ns/org# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio#" typeof="schema:CreativeWork sioc:Post prov:Entity">
    <main>
      <article about="" typeof="schema:ScholarlyArticle">
        <h1 property="schema:name">On a Web of Data Streams</h1>
        <div id="authors">
          <dl id="author-name">
            <dt>Authors</dt>
            <dd id="author-1"><span about="http://dellaglio.org" rel="schema:creator schema:publisher schema:author schema:author"><a about="#daniele" href="http://dellaglio.org" property="schema:name" rel="schema:url" typeof="schema:Person">Daniele Dell'Aglio</a></span><span about="#daniele" rel="schema:memberOf" resource="#UZH"></span><sup><a href="#author-org-1">1</a></sup><sup><a href="#author-email-a">a</a></sup></dd>

            <dd id="author-2"><span about="" rel="schema:author"><a about="#danh" href="http://data.semanticweb.org/person/danh-le-phuoc" property="schema:name" rel="schema:url" typeof="schema:Person">Danh Le Phuoc</a></span><span about="#danh" rel="schema:memberOf" resource="#tuberlin"></span><sup><a href="#author-org-2">2</a></sup><sup><a href="#author-email-b">b</a></sup></dd>

            <dd id="author-3"><span about="" rel="schema:author"><a about="#anh" href="https://www.insight-centre.org/users/anh-le-tuan" property="schema:name" rel="schema:url" typeof="schema:Person">Anh Le-Tuan</a></span><span about="#anh" rel="schema:memberOf" resource="#insight"></span><sup><a href="#author-org-3">3</a></sup><sup><a href="#author-email-c">c</a></sup></dd>

            <dd id="author-4"><span about="" rel="schema:author"><a about="#ali" href="http://intizarali.org/" property="schema:name" rel="schema:url" typeof="schema:Person">Muhammad Intizar Ali</a></span><span about="#ali" rel="schema:memberOf" resource="#insight"></span><sup><a href="#author-org-3">3</a></sup><sup><a href="#author-email-d">d</a></sup></dd>

            <dd id="author-5"><span about="" rel="schema:creator schema:publisher schema:author schema:author"><a about="#jpcik" href="https://w3id.org/people/jpcik/me" property="schema:name" rel="schema:url" typeof="schema:Person">Jean-Paul Calbimonte</a></span><span about="#jpcik" rel="schema:memberOf" resource="#HESSO"></span><sup><a href="#author-org-4">4</a></sup><sup><a href="#author-email-e">e</a></sup></dd>
          </dl>

          <ul id="author-org">
            <li id="author-org-1"><sup>1</sup><a about="#UZH" href="http://uzh.ch" property="schema:name" rel="schema:url" typeof="schema:Organization">University of Zurich</a>, <span class="adr"><span class="region">Zurich</span>, <span class="country-name">Switzerland</span></span></li>
            <li id="author-org-2"><sup>2</sup><a about="#tuberlin" href="http://tu-berlin.de" property="schema:name" rel="schema:url" typeof="schema:Organization">Technichal University of Berlin</a>, <span class="adr"><span class="region">Berlin</span>, <span class="country-name">Germany</span></span></li>
            <li id="author-org-3"><sup>3</sup><a about="#insight" href="https://insight-centre.org/" property="schema:name" rel="schema:url" typeof="schema:Organization">Insight Center for Data Analytics</a>, National University of Ireland, <span class="adr"><span class="region">Galway</span>, <span class="country-name">Ireland</span></span></li>
            <li id="author-org-4"><sup>4</sup><a about="#HESSO" href="http://www.hevs.ch" property="schema:name" rel="schema:url" typeof="schema:Organization">University of Applied Sciences and Arts Western Switzerland, HES-SO Valais-Wallis</a>, <span class="adr"><span class="region">Sierre</span>, <span class="country-name">Switzerland</span></span></li>
          </ul>

          <ul id="author-email">
            <li id="author-email-a"><sup>a</sup><a about="#daniele" href="mailto:dellaglio@ifi.uzh.ch" rel="schema:email">dellaglio@ifi.uzh.ch</a></li>
            <li id="author-email-b"><sup>b</sup><a about="#danh" href="mailto:danh.lephuoc@tu-berlin.de" rel="schema:email">danh.lephuoc@tu-berlin.de</a></li>
            <li id="author-email-c"><sup>c</sup><a about="#anh" href="mailto:anh.letuan@insight-centre.org" rel="schema:email">anh.letuan@insight-centre.org</a></li>
            <li id="author-email-d"><sup>c</sup><a about="#ali" href="mailto:ali.intizar@insight-centre.org" rel="schema:email">ali.intizar@insight-centre.org</a></li>
            <li id="author-email-e"><sup>d</sup><a about="#jpcik" href="mailto:jean-paul.calbimonte@hevs.ch" rel="schema:email">jean-paul.calbimonte@hevs.ch</a></li>
          </ul>
        </div>
 
        <div id="content">
          <section id="abstract">
            <h2>Abstract</h2>
            <div datatype="rdf:HTML" property="schema:abstract">
              <p>
               With the growing adoption of IoT and sensor technologies, an enormous amount of data
               is being produced at a very rapid pace and in different application domains.
               This sensor data consists mostly of live data streams containing sensor observations,
               generated in a distributed fashion by multiple heterogeneous infrastructures with minimal
               or no interoperability.
               RDF streams emerged as a model to represent data streams, and RDF Stream Processing (RSP)
               refers to a set of technologies to process such data.
               RSP research has produced several successful results and scientific output, but it can be
               evidenced that in most of the cases the Web dimension is marginal or missing.
               It also noticeable the lack of proper infrastructures to enable the exchange of RDF streams
               over heterogeneous and different types of RSP systems, whose features may vary
               from data generation to querying, and from reasoning to visualisation.
               This article defines a set of requirements related to the creation of a web of RDF stream
               processors.
               These requirements are then used to analyse the current state of the art, and to build a
               novel proposal, WeSP, which addresses these concerns.
              </p>
            </div>
          </section>
                      
          <section id="keywords">
            <h2>Keywords</h2>
            <div>
              <ul>
               <li>RDF stream</li>
               <li>RDF stream processing</li>
               <li>Interoperability</li>
               <li>Stream processing</li>
              </ul>
            </div>
          </section>
          
          <dl id="document-in-reply-to">
            <dt>In Reply To</dt>
            <dd><a href="http://iswc2017.desemweb.org/contributions/#research-articles" rel="as:inReplyTo">DeSemWeb2017 Call for Contributions</a></dd>
          </dl>  
            
          <section id="introduction" rel="schema:hasPart" resource="#introduction">
            <h2 property="schema:name" resource="#introduction" typeof="deo:Introduction">Introduction</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>
               The Web of Data (WoD) vision considers the Web as a distributed database: a vast—endless—amount of datasets to be accessed and queried.
               The <a href="http://lod-cloud.net/">Linking Open Data</a> (LOD) cloud is one of the most successful examples of such a vision:
               more than a thousand of datasets, owned and managed by different organisations, exposing
               interconnected data to be freely accessed.
               The data can be accessed in different ways, and the two most popular solutions are
               through dereferentiation and SPARQL.
               In the latter case, SPARQL is both a query language for the RDF data exposed in the
               LOD [<a href="#harris2013"></a>], and a protocol
               to exchange such data on the Web [<a href="#feigenbaum2013"></a>].
              </p>
              <p>
               Since the late 2000s, we have observed a trend that substantially increased the velocity
               aspect of part of this data.
               The Internet of Things (IoT) well exemplifies this: sensors create <em>streams</em>,
               defined as continuous sequences of data generated at very high frequencies, where its
               value is usually strictly associated to recency, i.e. the quicker the data is processed,
               the more valuable it is.
               It is therefore natural to ask if the existent WoD-related technologies are good enough
               to cope with such data.
               Looking at the research in the database area, it is possible to observe that the typical
               database approaches show several limitations while coping with data streams.
               Stonebraker et al. [<a href="#stonebraker2005"></a>] explain which are the requirements
               for processing streams, and highlight the limitations of DBMS approaches, e.g. their passive
               processing model works poorly with data characterised by extreme velocity; SQL does not
               support operators to cope with streams; and it is challenging to predict the behaviour
               of such systems while coping with streaming data.
               It is easy to observe that these limitations also affect SPARQL and existent WoD solutions.
              </p>
              <p>
               As a possible solution, Stream Processing Engines (SPEs) emerged in the area of data management
               research to cope with streaming data.
               They introduce new paradigms and processing models that fit better the requirements and
               scenarios involving data streams.
               As a result, new languages have been designed and developed, such as CQL [<a href="#arasu2006"></a>], <a href="https://docs.oracle.com/cd/E13157_01/wlevs/docs30/epl_guide/overview.html">EPL</a> and StreamSQL,
               with engines and systems designed with the specific task of processing streams.
              </p>
              <p>
               In the Web of Data, these novel paradigms inspired RDF Stream Processing (RSP): it builds
               on top of SPEs to mitigate the data heterogeneity issues by exploiting Semantic Web
               technologies.
               As the name suggests, such systems are designed to process data streams modelled through RDF,
               and they offer a wide set of operators, from typical SPE operations (e.g. filters,
               aggregations, event pattern matching) to reasoning features.
              </p>

              <table id="tab:overview">
                <caption>Comparison between data management and web of data paradigms</caption>
                <thead>
                  <tr>
                    <th></th><th>DB</th><th>SPE</th><th>WoD</th><th>WoDS</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>Processing</td>
                    <td>SQL</td>
                    <td>StreamSQL (et al.)</td>
                    <td>SPAR<b>QL</b></td>
                    <td>RSP-QL (et al.)</td>
                  </tr>
                  <tr>
                    <td>Data exchange</td>
                    <td>-</td>
                    <td>-</td>
                    <td>HTTP, S<b>P</b>ARQL</td>
                    <td>?</td>
                  </tr>
                </tbody>
              </table>

              <p>
               RSP fills an important gap between the current Web of Data and a Web of Data Streams (WoDS):
               it introduces models and languages to process streams on the Web, most of
               them captured by reference models as RSEP-QL [<a href="#dellaglio2016"></a>] and LARS
               [<a href="#beck2015"></a>].
               However, an important element is still missing, and it is a technical infrastructure
               to manage decentralized data exchange among RSP engines.
               As depicted in <a href="#tab:overview"></a>, data can be exchanged through HTTP (following the linked data principles) or via the SPARQL protocol.
               These solutions perfectly suit the cases where engines follow passive processing models,
               i.e. they pull the data when needed, but not when engines adopt active processing models.
              </p>
              <p>
               This study addresses the following research question: <em>what is a suitable data exchange
               infrastructure to perform stream processing on the Web?</em>
               In other words, this study intends to provide the bulding blocks of an infrastructure that
               enables the scenario depicted in <a href="#fig:overview"></a>: a network of RSP engines,
               distributed on the Web, able to exchange and process RDF streams among them.
              </p>
              <figure class="fig" id="fig:overview">
                <img src="img/overview.png" type="image/png" />
                <figcaption>The vision of WeSP: a network of RSP engines distributed on the Web, able to
                exchange RDF streaming data among them.</figcaption>
              </figure>
              <p>
               The solution should take into account the nature of the streams and the engines, as
               well as the technical characteristics of data exchange on the Web.
               It should indeed consider that existing RSP engines are heterogeneous in terms of operators
               and APIs to control them, as well as the nature of the Web, that is distributed and relies
               on existing technologies and standards.
               We envision a scenario as the one depicted in <a href="#fig:overview"></a>:
               interconnected RSPs that perform several tasks such as querying to reasoning, exchanging the
               results and producing sophisticated analyses.
              </p>
              <p>
               In the following, we present WeSP, a framework to build complex networks
               of RSP engines on the Web.
               WeSP defines a communication protocol to initialize the connection between
               two RSP engines and to manage the data exchange.
               This is implemented through two interfaces for the elements that produce and consume streams,
               and a vocabulary to annotate the streams.
               The design and implementation of WeSP takes into account existing previous
               results such as the W3C RSP Community Group <a href="https://www.w3.org/community/rsp">(RSP-CG)</a>
               reports, existing RSP engines, protocol and standards.
               We empirically show the feasibility of the WeSP approach for the construction
               of a Web of Data Streams, by proposing an implementation of its components with exiting RSP
               publishers and engines.
              </p>
              <p>
               The remainder of the article is structured as follows.
               We identify a set of requirements for communication of Web stream processors in
               <a href="#requirements"></a>.
               <a href="#framework-rdf-streams"></a> presents WeSP, describing its components
               and presenting an existing implementation in <a href="#implementation"></a>.
               In <a href="#related-work"></a>, we review the state of the art and we discuss
               the solutions available so far, before concluding with
               remarks and future directions in <a href="#conclusions"></a>.
              </p>
            </div>
          </section>

          <section id="requirements" rel="schema:hasPart" resource="#requirements">
            <h2 property="schema:name">Requirements</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>
               To design an infrastructure to exchange RDF streams on the Web, we first define a set
               of requirements.
               Three of them are extensions of Stonebraker et al.'s rules for building
               stream processing engines [<a href="#stonebraker2005"></a>], while others are
               elicited from real-world
               <a href="https://www.w3.org/community/rsp/wiki/Use_cases">use cases</a>.
              </p>
              <section id="sec:scenario-req-1">
                <h4 property="schema:name">R1: Keep the data moving</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   The first rule of [<a href="#stonebraker2005"></a>] states that a SPE "should use an
                   active (i.e., non-polling) processing model".
                   Looking at the WoD, we can notice that most of the interactions follow a polling paradigm
                   and are stateless.
                   This is a direct consequence of the client-server paradigm at the basis of HTTP and the
                   Web: servers supplying resources to client on demand.
                   In this sense, the traditional WoD is not the most suitable environment to perform stream processing.
                   Therefore, as first requirement, <em>WeSP must prioritize active
                   paradigms for data stream exchange, where the data supplier can <em>push</em> the stream
                   content to the actors interested in it</em>.
                  </p>
                </div>
              </section>
              <section id="sec:scenario-req-2">
                <h4 property="schema:name">R2: Stored and streamed data</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   The fifth rule of [<a href="#stonebraker2005"></a>] is about the "capability to
                   efficiently store, access and modify state information, and combine it with live
                   streaming data".
                   We need to revisit this rule from a WoD point of view, in particular about the notion
                   of stored data.
                   In this context, this data is represented by any dataset that is exposed to the Web
                   through SPARQL endpoints or through Linked Data technologies.
                   Our second requirement states that <em>WeSP must enable the
                   combination of streaming and stored data</em>.
                   In this case combination has a broad meaning, and may refer to several operations,
                   such as stream enrichment, stream storage or fact derivation.
                  </p>
                </div>
              </section>
              <section id="sec:scenario-req-3">
                <h4 property="schema:name">R3: High availability, distribution and scalability</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   The sixth rule of [<a href="#stonebraker2005"></a>] proposes to "ensure that the
                   applications are up and available, and the integrity of the data maintained at all
                   times, despite failures", while the seventh states that SPE "must be able to distribute
                   its processing across multiple processors and machines to achieve incremental scalability.
                   Ideally, the distribution should be automatic and transparent".
                   Even if such rules are mainly related to the stream processing engine architectures,
                   we can infer useful indications for the design of WeSP.
                   Our third requirement is that <em>WeSP must enable the possibility
                   to build reliable, distributed and scalable streaming applications</em>.
                  </p>
                </div>
              </section>
              <section id="sec:scenario-req-4">
                <h4 property="schema:name">R4: Operations on the stream content</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   Every use case has special requirements on the way the streaming data should processed.
                   Querying is an option when the goal is to aggregate, filter and look for relevant
                   patterns of events.
                   However, other alternatives are possible, such as deductive, inductive and other types
                   of reasoning; stream generation and visualization.
                   <em>WeSP must guarantee a wide range of operations over the streams</em>.
                   Such a requirement is important, in particular on the Web perspective, where data may
                   be accessed and used in unexpected ways by third-parties.
                  </p>
                </div>
              </section>
              <section id="sec:scenario-req-5">
                <h4 property="schema:name">R5: Accessible information about the stream</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   While the nature of the stream content is highly dynamic and volatile, the stream
                   itself is a resource that can be described.
                   Such descriptions are needed in a number of cases.
                   For example, statistics about the frequency and the size of the stream content may be
                   used to enable query optimization in the RSP engines; information about the generation
                   of the stream may be used to enable provenance-related reasoning; description of the
                   features of the streams may be collected in registries to achieve search and discovery.
                   Our fifth requirement states that <em>WeSP must support the
                   publication of stream descriptions</em>.
                  </p>
                </div>
              </section>
              <section id="sec:scenario-req-6">
                <h4 property="schema:name">R6: Stream variety support</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   The decentralised and bottom-up nature of the Web makes it hard—if not impossible—to define <em>the</em> model and serialization format for streams.
                   Looking at the use cases in the RSP-CG wiki, it is easy to observe that: streams can have
                   different velocity (e.g. one new item every minute vs every millisecond); time annotations
                   can be composed by zero, one, two or more time instants, item schemata can be simple (e.g.
                   numbers) or complex (e.g., graphs or tables).
                   To preserve the heterogeneity that characterizes the Web, <em>WeSP should
                   support the exchange of a wide variety of streams</em>.
                  </p>
                </div>
              </section>
              <section id="sec:scenario-req-7">
                <h4 property="schema:name">R7: Reuse of technologies and standards</h4>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   A common problem when building new frameworks and infrastructures is to find a good
                   trade-off among what is new and what exists.
                   On the one hand, creating everything from scratch is an opportunity to create a solution
                   that perfectly fits the requirements, but on the other hand adopting existing specifications
                   (i.e. standards and protocols) allows reusing existing tools and methods. 
                   This is particular true on the Web, where guaranteeing compatibility is mandatory in order
                   to enable interoperability.
                   Our last requirements states that the design of <em>WeSP should exploit
                   as much as possible existing protocols and standards</em>.
                  </p>
                </div>
              </section>
            </div>
          </section>

          <section id="framework-rdf-streams" rel="schema:hasPart" resource="#framework-rdf-streams">
            <h2 property="schema:name">A framework to exchange RDF streams on the Web</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>
                In this section we present our proposal to build an infrastructure to exchange RDF streams on the Web, WeSP. The design follows the requirements presented above, and it is composed by a data model for RDF streams, an API and a protocol to exchange the streams, and a model to describe the stream objects.
              </p>
              <section id="rdf-stream" rel="schema:hasPart" resource="#rdf-stream">
               <h3 property="schema:name">RDF stream: model and serialization</h3>
               <div datatype="rdf:HTML" property="schema:description">
                 <p>
                   Following the requirements and the type of scenarios that we address in this study,
                   it is needed to represent heterogeneous data streams, which can be shared by different
                   processing engines, and whose data can be not only retrievable but interpretable and
                   distributable among these engines.
                   The RDF model lends itself as a natural candidate for representing different types of data,
                   thanks to its flexibility in data modeling, and the usage of well established
                   standards, designed for the Web.
                   However, in order to be used in a streaming scenario, the RDF model may need extensions,
                   as shown in previous studies such as [<a href="#lephuoc2011"></a>, <a href="#barbieri2010"></a>].
                 </p>

                 <p>
                   We can distinguish two kinds of data in the requirements, first the streaming data,
                   which are by nature highly dynamic and labeled with time annotations.
                   Second, the contextual or background data, which changes less often, provides information that
                   enriches the streaming data (e.g. locations, profiles, producer data, system
                   descriptions).
                   For the latter, RDF graphs can be used as an underlying data model, while streams can be
                   captured using an extended RDF stream data model.
                 </p>
                 <p>
                   To fulfil these goals, we adopt the notion of time-annotated RDF graphs as elements
                   of RDF streams, following the <a href="https://w3id.org/rsp/abstract-model">abstract data model</a> proposed by the W3C RSP Community Group.
                 </p><!--
                 <p>
                   We define a <em>timeline</em> \(T\) as an infinite, ordered sequence of time entities
                   \((t_1, t_2,\ldots)\), where \(t_i{\in}\mbox{ TimeEntities}\)
                   and for all \(i{>}0\), it holds that \(t_{i}\) happened before \(t_{i+1}\). When the time
                   entities are restricted to instants, \(t_{i+1}-t_i\) is a constant,
                   i.e. the <em>time unit</em> of \(T\).
                 </p>

                 <p>
                   Following the definitions in [<a href="#dellaglio2016"></a>], the definition of RDF streams
                   can be formulated as an extension of RDF Graphs with time annotations.
                 </p>


                 <h4>RDF Stream</h4>
-->
                 <p>
                   The proposal introduces a notion of RDF stream as a sequence of time-annotated named graphs (<em>timestamped graph</em>). Each graph can have different time annotations, identified through <em>timestamp predicates</em>.
                 </p>

                 <p>
                   As an example, we can consider the case where each graph has a time annotation. We define a <em>timeline</em> \(T\) as an infinite, ordered sequence of time entities
                   \((t_1, t_2,\ldots)\), where \(t_i{\in}\mbox{ TimeEntities}\)
                   and for all \(i{>}0\), it holds that \(t_{i}\) happened before \(t_{i+1}\). When the time
                   entities are restricted to instants, \(t_{i+1}-t_i\) is a constant,
                   i.e. the <em>time unit</em> of \(T\).
                   An RDF stream is a sequence of pairs \((G, t)\), where \(G\) is an RDF graph and \(t\in T\) is a time entity:
<!--
                   An <em>RDF stream</em> \(S\) is a (potentially) unbounded
                   sequence of timestamped RDF graphs in a non-decreasing time order:
-->

                   <figure class="equation" typeof="doco:FormulaBox">
                     $$S=(G_1,t_1),(G_2,t_2),(G_3,t_3),(G_4,t_4),\ldots$$
<!-- this is hell
                     <math xmlns="http://www.w3.org/1998/Math/MathML">
                       <mi>S</mi><mo>=</mo>
                       <mo>(</mo><msub><mi>G</mi><mn>1</mn></msub><mo>,</mo><msub><mi>t</mi><mn>1</mn></msub><mo>)</mo><mo>,</mo>
                       <mo>(</mo><msub><mi>G</mi><mn>2</mn></msub><mo>,</mo><msub><mi>t</mi><mn>2</mn></msub><mo>)</mo><mo>,</mo>
                       <mo>(</mo><msub><mi>G</mi><mn>3</mn></msub><mo>,</mo><msub><mi>t</mi><mn>3</mn></msub><mo>)</mo><mo>,</mo>
                       <mo>(</mo><msub><mi>G</mi><mn>4</mn></msub><mo>,</mo><msub><mi>t</mi><mn>4</mn></msub><mo>)</mo><mo>,</mo>
                       <mo>&#x2026;</mo>
                     </math>
-->
                   </figure>

                   where, for every \(i>0\), \((G_i,t_i)\) is a timestamped RDF graph and \(t_i \leq t_{i+1}\).
                 </p>
                 <p>
                   The following stream \(S\) is compliant with the above model:
                     $$S{=}(G_1,2),(G_2,4),(G_3,6),(G_4,8),(G_5,10),\ldots,$$
                   where each \(G_i\) contains the depicted RDF triples in <a href="#fig:streamexample"></a>.
                 </p>
                 <figure class="fig" id="fig:streamexample">
                   <img src="img/streamexample.png" type="image/png" />
                   <figcaption>An example of time annotated graphs on an RDF Stream.</figcaption>
                 </figure>

                 <p>
                   This model can be serialized using current standards for RDF representation, as depicted in <a href="#list:example"></a>. The listing shows a JSON-LD representation of a
                   timestamped graph,annotated using the <a href="https://www.w3.org/TR/prov-o/">PROV</a>
                   <em>generatedAtTime</em> property. In this case the graph contents include the graph G<sub>2</sub> of
                   <a href="#fig:streamexample"></a>.
                 </p>

                 <figure class="listing" id="list:example">
                   <pre><code>{"prov:generatedAtTime": "2015-06-30T04:00:00.000Z",</code>
<code> "@id": "wesp:G2",</code>
<code> "@graph": [</code>
<code>  { "@id": "wesp:a2",</code>
<code>    "wesp:p": {"@id":"wesp:b2"}</code>
<code>  }],</code>
<code> "@context": {</code>
<code>    "prov": "http://www.w3.org/ns/prov#",</code>
<code>    "wesp": "http://streamreasoning.org/wesp/"</code>
<code>}</code></pre>
                   <figcaption>Example of a timestamped graph represented using JSON-LD.</figcaption>
                 </figure><!--
                 <figure class="listing" id="list:example">
                   <pre style="font-size:0.7em;">
<code>{"http://www.w3.org/ns/prov#generatedAtTime": "2015-06-30T16:44:59.587Z",</code>
<code> "@id": "http://streamreasoning.org/TripleWave/ak10992887",</code>
<code> "@graph": [</code>
<code>  { "@id": "http://streamreasoning.org/TripleWave/ak10992887",</code>
<code>    "@type": "cbench:TrafficObservation",</code>
<code>    "ssn:observedProperty": "cbench:TrafficData",</code>
<code>    "ssn:hasValue": "32",</code>
<code>    "ssn:observedBy": "ins-event:AarhusTrafficData158505"</code>
<code>  }],</code>
<code> "@context": {</code>
<code>    "ssn": "http://www.w3.org/2002/12/cal/ical#",</code>
<code>    "cbench": "http://www.insight-centre.org/citytraffic#",</code>
<code>    "ins-event": "http://www.insight-centre.org/dataset/SampleEventService#"</code>
<code>}</code></pre>
                   <figcaption>Example of a timestamped graph represented using JSON-LD.</figcaption>
                 </figure>
-->
                 <p>
                   In the remaining of this contribution, we consider this model where the time annotation is represented by one time instant. The choice is without loss of generality, since WeSP can be used to exchange other types of streams.
                 </p>
               </div>
             </section>

              <section id="protocol" rel="schema:hasPart" resource="#protocol">
               <h3 property="schema:name">Communication protocol</h3>
               <div datatype="rdf:HTML" property="schema:description">
                 <p>
                   WeSP defines two interfaces, namely <em>producer</em> and <em>consumer</em>.
                   As the names suggest, the former is implemented by actors that distribute streams
                   across the Web, while the latter is implemented by actors who want to receive streams.
                 </p>

                 <p>
                   Every actor involved in the processing may implement either interface, as well as both
                   of them. This leads us to the following nomenclature.
                   A <em>stream source</em> implements the producer interface only. Services exposing sensors
                   data on the Web and TripleWave [<a href="#mauri2016"></a>] are examples of stream sources.
                   Similarly, a <em>stream sink</em> implements the consumer interface only, e.g. a dashboard
                   visualising information for the final user.
                   Finally, a <em>stream transformer</em> implements both the interfaces: it gets as input a
                   stream and outputs another stream, e.g. a stream processor or a stream reasoner.
                 </p>

                 <p>
                   The principal responsibility of the producers is to make streaming data accessible. It is
                   done by exposing <em>Stream Descriptors</em>, i.e. metadata about the streams.
                   Examples of Stream Descriptor contents are the creator, the adopted vocabulary and statistical
                   information about the stream.
                   However, the most relevant data the Stream Descriptor brings is about how to effectively access
                   the stream content.
                   We detail the stream descriptor in <a href="#stream-descriptor">Section 3.3</a>. In the following, we describe how the producer/consumer communication develops.
                 </p>

                 <figure class="fig" id="fig:protocol">
                   <img src="img/consume.png" type="image/png" />
                   <figcaption>Protocol to establish the communication between the producer and the consumer
                   interfaces</figcaption>
                 </figure>

                 <p>
                   The communication relies on two phases, depicted in <a href="#fig:protocol"></a>, and it
                   starts on the consumer side (as in typical push-based communication).
                   The consumer only needs to be aware of the IRI of the Stream Descriptor, e.g. the user
                   provides it as an instruction to the constructor.
                   This is what is needed for the first phase, where the consumer accesses the Stream Descriptor
                   IRI (as in <a href="#fig:protocol"></a>) through an HTTP request, following the
                   Linked Data principles.
                 </p>
                 <p>
                   In the second phase, the consumer starts to receive the stream (as in
                   <a href="#fig:protocol"></a>).
                   The Service Descriptor brings information about how to access the effective stream content.
                   That means, it describes one or more ways to establish the connection between the consumer and
                   the endpoint that is providing the stream content.
                   This connection can happen with different protocols, based on push mechanisms. e.g. WebSocket
                   and <a href="mqtt.org/">MQTT</a>, as well as based on pull mechanisms, e.g. HTTP.
                   Among the several options offered by the producer through the Service Descriptor, consumers
                   choose the way they prefer.
                   After the decision, the consumer can start to receive the stream content and to process it.
                 </p>
                 <p>
                   The choice to allow several channels to distribute the streams gives the freedom to
                   adopt several channels to exchange the streams, relying on different technologies based on
                   requirements of the specific scenario.
                 </p>
               </div>
             </section>

              <section id="stream-descriptor" rel="schema:hasPart" resource="#stream-descriptor">
               <h3 property="schema:name">Stream Descriptor</h3>
               <div datatype="rdf:HTML" property="schema:description">
                 <p>
                   The Stream Descriptor is an RDF document providing metadata of the RDF stream that is used by a
                   <em>consumer</em> for bootstrapping its stream consuming process.
                   Realizing that an RDF stream is similar to an RDF dataset, we extend the
                   <a  href="https://www.w3.org/TR/vocab-dcat/">DCAT vocabulary</a> to represent an RDF
                   Stream as illustrated in <a href="#fig:schema"></a> (and available 
                   <a href="https://dellaglio.github.io/webstreams/rs-onto.ttl">here</a>).
                 </p>
                 <p>
                   The class RDFStream extends dcat:DataSet to inherit all properties of a RDF dataset, and
                   it also offers properties specific to a stream, such as <em>streamrate</em> and <em>streamTemplate</em>.
                   The <em>streamTemplate</em> property can be used to point to a document that specifies the
                   template or the constraint of the RDF stream, for instance, the template can be an RDF
                   constraint document described using <a href="https://www.w3.org/TR/shacl/">SHACL</a>.
                   The template can be used as a hint of the data shape of the RDF stream for the consumer to
                   optimize its processing.
                   It also plays the role as a validation rule for consumer to verify if the incoming data is conformed with the template.
                 </p>
                 <figure class="fig" id="fig:schema">
                   <img src="img/sd-model.png" type="image/png" />
                   <figcaption>Description of RDF Stream</figcaption>
                 </figure>
                 <p>
                   Note that an RDF stream can be distributed via different stream channels using different protocols, like HTTP and Websocket.
                   Therefore, a stream channel is an instance of the RDFStreamPublisher class which is linked
                   to the RDFStream class via the property <em>dcat:distribution</em>.
                   The RDFStreamPublisher is used to specify the protocol and the URL whereby the consumer can
                   tap into to receive the stream.
                   Also, RDFStreamPublisher is a subclass of the dcat:Distribution class which has several
                   properties for the consumer to configure its parsers such as <em>dcat:mediaType</em> and
                   <em>dcat:format</em>.
                   An RDFStreamPublisher might provide a continuous query service which is specified by the
                   RSPService class extended from the sd:Service defined by
                   <a href="https://www.w3.org/TR/sparql11-service-description/">SPARQL 1.1 Service description</a>.
                   <!--
                   As most of RSP engines extend SPARQL 1.1 for their query languages, using the federated service
                   vocabularies will provide useful vocabularies for describing RDF continuous querying services
                   powered by RSP engines such as C-SPARQL and CQELS.
                 -->
                 </p>
                 <figure class="listing">
                   <pre><code>{"@context": {</code>
<code>  "wesp": "http://streamreasoning.org/wesp/",</code>
<code>  "generatedAt": { </code>
<code>   "@id": "http://www.w3.org/ns/prov#generatedAtTime",</code>
<code>   "@type": "http://www.w3.org/2001/XMLSchema#dateTime" </code>
<code>  }</code>
<code> },</code>
<code> "@type": "wsd:RDFStream",</code>
<code> "dcat:accessURL": "ws://localhost/streams/S",</code>
<code> "wsd:streamTemplate": {"@id":"http://purl.oclc.org/NET/ssnx/ssn"},</code>
<code> "wsd:shacl": {</code>
<code>  "@list": [</code>
<code>   {</code>
<code>     "generatedAt": "2015-06-30T02:00:00.000Z", </code>
<code>     "@id": "wesp:G1" </code>
<code>   },{</code>
<code>     "generatedAt": "2015-06-30T04:00:00.000Z", </code>
<code>     "@id": "wesp:G2" </code>
<code>   },{ </code>
<code>     "generatedAt": "2015-06-30T06:00:00.000Z", </code>
<code>     "@id": "wesp:G3" </code>
<code>   }</code>
<code>  ]</code>
<code> },</code>
<code> "sld:lastUpdated": "2015-06-30T06:00:00.000Z"</code>
<code>}</code>
                   </pre>
                   <figcaption>The Stream Descriptor associated to the stream in <a href="#fig:streamexample"></a>.</figcaption>
                 </figure>
                 </div>
             </section>
            </div>
          </section>

          <section id="implementation" rel="schema:hasPart" resource="#implementation">
            <h2 property="schema:name">Implementation and examples</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>
                In this section, we describe three implementations of WeSP.
                The first is a stream source, the others are stream transformers. They are built on top of existing frameworks, TripleWave and C-SPARQL [<a href="#barbieri2010"></a>] and CQELS [<a href="#lephuoc2011"></a>].
                All the related code is open source under <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache 2.0 Licence</a> and is available online.
              </p>
              <section id="triplewave" rel="schema:hasPart" resource="#triplewave">
                <h3 property="schema:name">Stream source example: TripleWave</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   TripleWave [<a href="#mauri2016"></a>] is a framework to create and expose RDF streams
                   according to the producer interface described above.
                   Triplewave can be fed with different input, such as non-RDF Web streams or RDF data
                   containing temporal annotations.
                  </p>

                  <p>
                   In the former case, TripleWave lifts existing Web streams as RDF streams, such as the
                   <a href="https://en.wikipedia.org/wiki/Special:RecentChanges">Wikipedia update stream</a>
                   and <a href="https://dev.twitter.com/streaming/overview">Twitter stream</a>.
                   The operation is enabled through R2RML transformations [<a href="#das2012"></a>], that map
                   relational to RDF data.
                   The lifting operation enables the interoperability among the WeSP actors, addressing R6.
                  </p>

                  <p>
                   In the latter case, TripleWave streams out data stored in a repository.
                   This mode is useful for benchmarking as well as experimental runs, where data has to be
                   streamed multiple times across the network.
                   Precondition to this mode is the existence of time information associated to the repository
                   content: TripleWave uses them to compute the correct intervals between consecutive events and
                   set delays accordingly.
                  </p>

                  <p>
                   TripleWave has been extended to natively support WeSP, as it implements the producer interface.
                   It can spread the streams through WebSocket, MQTT and HTTP chunked encoding. Support for <a href="https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events">Server-Sent Events</a> (SSE) will be released soon. This offers to consumers a wide choice on the protocol to be used to receive the data, according to the use case requirements and on the system needs.
                   The endpoints related to the protocols, as well as the required information to access them, are described in RDF and embed in the Stream Descriptor, exposed on an HTTP address. The code and the instructions are available at the <a href="http://streamreasoning.github.io/TripleWave">project page</a>.
                  </p>
                </div>
              </section>

              <section id="stream-transformer" rel="schema:hasPart" resource="#stream-transformer">
                <h3 property="schema:name">Stream transformer example: C-SPARQL and CQELS</h3>
                <div datatype="rdf:HTML" property="schema:description">
                  <p>
                   It is possible to create WeSP actors out of existing stream processors by introducing adapters.
                   We depict this possibility by presenting the cases of C-SPARQL [<a href="#barbieri2010"></a>]
                   and CQELS [<a href="#lephuoc2011"></a>], two engines able to processing streams through continuous query languages based on SPARQL [<a href="#harris2013"></a>].
                  </p>
                  <p>
                    These engines offer programmatic APIs to manage the communication, i.e. (i) declare RDF streams, (ii) push the stream items into the declared RDF Streams, (iii) register the query, (iv) register listeners to obtain and manage query results.
                    The WeSP adapter should implement the producer and consumer interfaces according to such APIs.
                  </p>
                  <p>
                    The implementation of the consumer interface in the adapter should enable the connection to a
                    stream source or transformer, according to the protocol described above.
                    Given the nature of such engines, the control of the engine should happen in a query-driven way.
                    That means, when a new query is registered, the engine should establish the connections for the
                    streams needed to evaluate the query.
                    The main problem is related to the discovery of the streams: how to let the engine know where
                    the streams are?
                    The solution we propose is based on the following consideration: both the languages adopted by
                    the engines (respectively C-SPARQL and CQELS-QL) offer the possibility to declare the stream
                    through a IRI.
                    If such IRI denotes a Stream Descriptor address, engines would have the information they need to
                    establish the connection.
                  </p>
                  <p>
                    Similarly to the consumption, the stream production is query driven. RSP engines stream out the
                    query results and make it available to other agents (e.g. users, other engines, etc.).
                    The WeSP adapter implements the producer interface as follows. For each query that is registered
                    in the engine, the adapter performs two actions.
                    First, it creates a Stream Descriptor and exposes it at an HTTP address.
                    Second, it registers a listener to manage the answers.
                    The current implementation provides the listeners for MQTT and WebSocket.
                    The first forwards the results to a MQTT broker, while the latter sends the result to an internal component that manages the ongoing connections.
                    In this way, several actors may access the results of the same query.
                  </p>
                  <p>
                    The code for C-SPARQL is available on <a href="https://github.com/dellaglio/csparql-wesp">GitHub</a>.
                    The library embeds the C-SPARQL engine in a Java class that implements the consumer and producer interfaces.
                    The result is transparent, in the sense that the new main class exposes the same methods of the C-SPARQL original one.
                    In this way, no additional effort is put on the user side, which can benefit of WeSP without learning to use new APIs.
                  </p>
                  <p>
                    The code for CQELS is available in the official CQELS <a href="https://github.com/cqels/CQELS-1.x/">repository</a>.
                    In this case, we opted for the integration of the WeSP interface directly in the main project.
                    The current version supports the data stream exchange via WebSocket, but we plan to integrate other protocols as future work.
                  </p>
                </div>
              </section>
            </div>
          </section>


          <section id="related-work" rel="schema:hasPart" resource="#related-work">
            <h2 property="schema:name" resource="#related-work" typeof="#related-work">Related Work</h2>

            <div datatype="rdf:HTML" property="schema:description">
              <p>
                RSP (RDF Stream Processing) engines emerged in recent years, with the goal of extending RDF
                and SPARQL to process RDF streams.
                They can be broadly divided into two groups. The first is of those influenced by Complex Event
                Processing (CEP), e.g. EP-SPARQL [<a href="#anicic2011"></a>], Sparkwave [<a href="#komazec2012"></a>]
                and Instans [<a href="#rinne2012"></a>].
                the second group is that of engines inspired by DSMS, which exploit sliding window mechanisms
                to capture a finite portion of the input data. Examples include C-SPARQL [<a href="#barbieri2010"></a>],
                CQELS [<a href="#lephuoc2011"></a>], and SPARQL<sub>stream</sub> [<a href="#calbimonte2012"></a>].
                While these engines provide querying features, they generally lack the means to publish or reuse RDF data
                streams on the Web. Instead, they assume ad-hoc connection to RDF streams without any protocol of
                communication. 
              </p>
              <p>
                An inital effort targeting communication and interchange among RSP engines, named
                RSP Services, was proposed in [<a href="#balduini2013a"></a>].
                The goal of this project is to enable remote control of RSP engines, which is achieved by introducing REST APIs that exposes the programmatic APIs of the RSP engines, and by Web
                Socket channels to connect engines. So far, <a href="https://github.com/streamreasoning/rsp-services-csparql">an implementation</a> for C-SPARQL exists. This project has limitations given the heterogeneity and difficulty of handling the engines in a uniform manner: not all the engines work based on queries, so it may not be enough to cover a wider range of RDF stream processing engines, such as stream reasoners.
                WeSP targets the problem of exhanging RDF streams between engines, not only query engines; it supports a wider range of communication protocols and a richer  description of the stream (through the stream descriptor).
              </p>
              <p>
                Regarding the publication of streams on the Web using RDF technologies, we can mention
                [<a href="#gerber2013"></a>, <a href="#trinh2014"></a>], which proposes the generation of RDF datasets out of
                unstructured streams. Other works focused on the usage of Linked Data principles for publishing streams
                [<a href="#balduini2013"></a>,<a href="#lephuoc2012"></a>], although they did not provide any further
                communication or interchange protocol beyond the standard principles used in static and stored data.
              </p>
              <p>
                The stream publishing implementation of WeSP relies on <a href="http://streamreasoning.github.io/TripleWave/">TripleWave</a> [<a href="#mauri2016"></a>], a generic and RDF stream-oriented publication system tailored for the Web. It goes beyond
                previous works, providing a generic framework for RDF stream provision, including ingestion of non-RDF sources and time-annotated RDF datasets. TripleWave introduced the notion of stream descriptor. As explained in <a href="#implementation"></a>, in the context of this study we extended TripleWave with a new stream descriptor vocabulary and extension to new communication protocols such as MQTT.
              </p>
              <p>
                The work of the W3C RDF Stream Processing Community Group (RSP-CG) provides a starting point towards
                a common model for representing, querying and exchanging RDF stream data. However, given the scope of the
                group, the published reports on <a href="https://w3id.org/rsp/requirements">
                Requirements and Design Principles</a>, as well as the <a href="https://w3id.org/rsp/abstract-syntax">Abstract model</a>, do not propose a concrete
                set of interfaces and serialization formats for enabling interchange and interoperability. In WeSP
                we take into consideration the abstract model and guidelines of the RSP-CG, taking it to the implementation level.
                Another related specification, the <a href="https://www.w3.org/TR/ldn/">Linked Data Notifications</a> (LDN)
                recommendation of W3C, targets a very generic scenario of Linked Data senders, receivers and consumers.
                While this specification is too generic for the streaming data requirements presented in <a href="#requirements"></a>,
                it might be worth to explore commonalities between LDN and this work.
              </p>
              <p>
                Finally, outside of the RDF and Semantic Web technologies, different technologies and protocols have been developed
                for supporting data stream communication and exchange, often linked to the Internet of Things. Protocols
                include MQTT, WebSockets, or streaming HTTP-based solutions such as SSE (Server-Sent Events).
                In this work, these different options can be encapsulated under a higher-level protocol, allowing the
                co-existence of different underlying technologies.
              </p>
            </div>
          </section>

          <section id="conclusions" rel="schema:hasPart" resource="#conclusions">
            <h2 property="schema:name" resource="#conclusions" typeof="deo:Conclusion">Conclusions</h2>
            <div datatype="rdf:HTML" property="schema:description">
              <p>
                In this contribution, we presented WeSP, a framework to exchange RDF streams. WeSP moves a step towards the
                realization of an eco-system of Web stream engines, where engine has a broad meaning and can refer to stream
                sources, visualisers, continuous query systems and stream reasoners. In future work we we aim at continuing
                the development of WeSP. In particular, we are interested in studying the relation with other studies, such as
                [<a href="#taelman2016"></a>], LDN and <a href="https://www.w3.org/TR/activitystreams-core/">Activity Streams </a>,
                adopting and integrating them when possible.
              </p>
              <p>
                We designed WeSP based on a set of requirements elicited from literature and real use cases, and as a result, it
                builds on existing technologies and recommendations, such as RDF, WebSocket and MQTT.
                We have shown the feasibility of the approach by presenting concrete implementations, available as open source projects.
                We believe that a wide availability of Web stream engines can enable research in future interesting work directions,
                such as federated query processing or, more in general, federated stream processing over the Web.
              </p>
            </div>
          </section>


          <section id="references">
            <h2>References</h2>
            <div>
             <ol>
                <li id="anicic2011">
                  D. Anicic, P. Fodor, S. Rudolph, and N. Stojanovic.
                  EP-SPARQL: a unified language for event processing and stream reasoning.
                  In <em>WWW</em>, pages 635-644, 2011. 
                  <a href="http://www.aifb.kit.edu/images/c/c0/Www29-anicic.pdf" property="schema:citation">[online]</a></li>
 		            <li id="arasu2006">A. Arasu, S. Babu, J. Widom.
		  The CQL continuous query language: semantic foundations and query execution. 
		  In <em>VLDB J.</em> 15(2), pages 121-142, 2006.
		  <a href="http://ilpubs.stanford.edu:8090/758/1/2003-67.pdf" property="schema:citation">[online]</a></li>
                <li id="balduini2013a">
                  M. Balduini and E. Della Valle.
                  A restful interface for RDF stream processors.
                  In <em>ISWC 2013 Posters &amp; Demonstrations Track</em>, pages 209-212, 2013.
                  <a href="http://ceur-ws.org/Vol-1035/iswc2013_poster_8.pdf" property="schema:citation">[online]</a></li>
                <li id="balduini2013">
                  M. Balduini, E. Della Valle, D. Dell'Aglio, M. Tsytsarau, T. Palpanas, and C. Confalonieri.
                  Social Listening of City Scale Events Using the Streaming Linked Data Framework.
                  In <em>ISWC</em>, pages 1-16. 2013.
                  <a href="http://disi.unitn.it/~themis/publications/iswc13.pdf" property="schema:citation">[online]</a></li>
                <li id="barbieri2010" property="schema:citation">
                  D. F. Barbieri, D. Braga, S. Ceri, E. Della Valle, and M. Grossniklaus.
                  C-SPARQL: a Continuous Query Language for RDF Data Streams.
                  <em>Int. J. Semantic Computing</em>, 4(1):3-25, 2010. 
                  <a href="https://doi.org/10.1142/S1793351X10000936" property="schema:citation">[online]</a> </li>
                <li id="barbieri2010a">
                  D. F. Barbieri and E. Della Valle.
                  A proposal for publishing data streams as linked data - A position paper.
                  In <em>LDOW</em>, 2010.
                  <a href="http://ceur-ws.org/Vol-628/ldow2010_paper11.pdf" property="schema:citation">[online]</a></li>
                <li id="beck2015">
                  Beck, H., Dao-Tran, M., Eiter, T., and Fink, M.
                  LARS: A Logic-Based Framework for Analyzing Reasoning over Streams.
                  In <em>AAAI</em>, pages 1431-1438, 2015.
                  <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9657/9415" property="schema:citation">[online]</a></li>
                <li id="calbimonte2012">
                  J.-P. Calbimonte, H. Jeung, O. Corcho, and K. Aberer.
                  Enabling query technologies for the semantic sensor web.
                  <em>Int. J. Semantic Web Inf. Syst.</em>, 8:43-63, 2012.
                  <a href="http://jeanpi.org/wp/media/ijswis_calbimonte_submission_images.pdf" property="schema:citation">[online]</a></li>
                <li id="das2012">
                  S. Das, S. Sundara, and R. Cyganiak. R2rml: RDB to RDF Mapping Language.
                  W3C Recommendation, W3C, 2012.
                  <a href="https://www.w3.org/TR/r2rml/" property="schema:citation">https://www.w3.org/TR/r2rml/</a></li>
                <li id="dellaglio2016">
                  D. Dell'Aglio, M. Dao-Tran, J.-P. Calbimonte, D. L. Phuoc, and E. Della Valle.
                  A Query Model to Capture Event Pattern Matching in RDF Stream Processing Query Languages.
                  In <em>EKAW</em>, pages 145-162, 2016.
                  <a href="http://www.kr.tuwien.ac.at/staff/dao/pub/2016/AQueryModeltoCaptureEventPatternMatchinginRDFStreamProcessingQueryLanguages-ekaw.pdf" property="schema:citation">[online]</a></li>
                <li id="feigenbaum2013">
                  L. Feigenbaum, G. T. Williams, K. G. Clark, and E. Torres.
                  SPARQL 1.1 Protocol.
                  W3C Recommendation, W3C, 2013.
                  <a href="https://www.w3.org/TR/sparql11-protocol/" property="schema:citation">https://www.w3.org/TR/sparql11-protocol/</a></li>
                <li id="fisteus2014">
                  J. A. Fisteus, N. F. Garcia, L. S. Fernandez, and D. Fuentes-Lorenzo.
                  Ztreamy: A middleware for publishing semantic streams on the web.
                  <em>J. Web Semantics</em>, 25:16-23, 2014.
                  <a href="http://www.imap.websemanticsjournal.org/preprints/index.php/ps/article/download/350/372" property="schema:citation">[online]</a></li>
                <li id="gerber2013">
                  D. Gerber, S. Hellmann, L. Bühmann, T. Soru, R. Usbeck, and A.-C. N. Ngomo.
                  Real-time rdf extraction from unstructured data streams.
                  In <em>ISWC</em>, pages 135-150. 2013.
                  <a href="http://svn.aksw.org/papers/2013/ISWC_RdfLiveNews/public_preprint.pdf" property="schema:citation">[online]</a></li>
                <li id="harris2013">
                  S. Harris and A. Seaborne.
                  SPARQL 1.1 Query Language. W3c Recommendation, W3C, 2013.
                  <a href="https://www.w3.org/TR/sparql11-query/" property="schema:citation">https://www.w3.org/TR/sparql11-query/</a></li>
                <li id="komazec2012">
                  S. Komazec, D. Cerri, and D. Fensel.
                  Sparkwave: continuous schema-enhanced pattern matching over RDF data streams.
                  In <em>DEBS</em>, pages 58-68. 2012.
                  <a href="http://www.davidecerri.it/wp-content/uploads/2016/02/art-sparkwave-debs2012.pdf" property="schema:citation">[online]</a></li>
                <li id="lephuoc2011">
                  D. Le Phuoc, M. Dao-Tran, J. X. Parreira, and M. Hauswirth.
                  A Native and Adaptive Approach for Unified Processing of Linked Streams and Linked Data.
                  In <em>ISWC</em>, pages 370-388. 2011.
                  <a href="http://iswc2011.semanticweb.org/fileadmin/iswc/Papers/Research_Paper/05/70310368.pdf">[online]</a></li>
                <li id="lephuoc2012">
                  D. Le-Phuoc, H. Q. Nguyen-Mau, J. X. Parreira, and M. Hauswirth.
                  A middleware framework for scalable management of linked streams.
                  <em>J. Web Semantics</em>, 16:42-51, 2012.
                  <a href="http://www.manfredhauswirth.org/research/papers/JoWS2012.pdf" property="schema:citation">[online]</a></li>
                <li id="mauri2016">
                  A. Mauri, J.-P. Calbimonte, D. Dell'Aglio, M. Balduini, M. Brambilla, E. D. Valle, and K. Aberer.
                  TripleWave: Spreading RDF Streams on the Web.
                  In <em>ISWC</em>, pages 140-149, 2016.
                  <a href="http://publications.hevs.ch/index.php/attachments/single/1182" property="schema:citation">[online]</a></li>
                <li id="rinne2012">
                  M. Rinne, S. Törmä, and E. Nuutila.
                  SPARQL-based applications for RDF encoded sensor data.
                  In <em>SSN</em>, volume 904, pages 81-96. 2012.
                  <a href="http://ceur-ws.org/Vol-904/paper15.pdf" property="schema:citation">[online]</a></li>
                <li id="schmidt2011">
                  M. Schmidt, O. Görlitz, P. Haase, G. Ladwig, A. Schwarte, and T. Tran.
                  Fedbench: A benchmark suite for federated semantic data query processing.
                  In <em>ISWC</em>, pages 585-600. 2011.
                  <a href="http://iswc2011.semanticweb.org/fileadmin/iswc/Papers/Research_Paper/05/70310576.pdf" property="schema:citation">[online]</a></li>
                <li id="schwarte2011">
                  A. Schwarte, P. Haase, K. Hose, R. Schenkel, and M. Schmidt.
                  Fedx: A federation layer for distributed query processing on linked open data.
                  In <em>ESWC</em>, pages 481-486. 2011.
                  <a href="http://www.fluidops.com/downloads/documents/pubeswc2011fedx.pdf" property="schema:citation">[online]</a></li>
                <li id="stonebraker2005">
                  M. Stonebraker, U. Cetintemel, and S. B. Zdonik.
                  The 8 requirements of real-time stream processing. 
                  SIGMOD Record, 34(4):42-47, 2005.
                  <a href="http://www09.sigmod.org/sigmod/record/issues/0512/p42-article-stonebraker.pdf" property="schema:citation">[online]</a></li>
                <li id="taelman2016">
                  R. Taelman, P. Heyvaert, R. Verborgh, E. Mannens.
                  Querying Dynamic Datasources with Continuously Mapped Sensor Data.
                  In <em>ISWC (Posters &amp; Demos)</em>, 2016.
                  <a href="http://ceur-ws.org/Vol-1690/paper6.pdf" property="schema:citation">[online]</a></li>
                <li id="trinh2014">
                  T.-D. Trinh, P. Wetz, B.-L. Do, A. Anjomshoaa, E. Kiesling, and A. M. Tjoa.
                  A web-based platform for dynamic integration of heterogeneous data.
                  In <em>IIWAS</em>, pages 253-261, 2014.
                  <a href="https://publik.tuwien.ac.at/files/PubDat_235082.pdf" property="schema:citation">[online]</a></li>
             </ol>
            </div>
          </section>
        </div>
      </article>
    </main>
  </body>
</html>
