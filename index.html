<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <meta charset="utf-8" />
        <title>Web Streams Paper</title>
        <link rel="stylesheet" href="https://dokie.li/media/css/lncs.css" media="all" title="LNCS" />
        <link rel="stylesheet alternate" href="https://dokie.li/media/css/acm.css" media="all" title="ACM" />
        <link rel="stylesheet alternate" href="https://www.w3.org/StyleSheets/TR/W3C-ED.css" media="all" title="W3C-ED"/>
        <link rel="stylesheet" href="https://dokie.li/media/css/do.css" media="all" />
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" media="all" />
        <script src="https://dokie.li/scripts/simplerdf.js"></script>
        <script src="https://dokie.li/scripts/medium-editor.min.js"></script>
        <script src="https://dokie.li/scripts/medium-editor-tables.min.js"></script>
        <script src="https://dokie.li/scripts/do.js"></script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

    </head>

    <body about="" prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ v: http://www.w3.org/2006/vcard/ns# pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# cal: http://www.w3.org/2002/12/cal/ical# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# org: http://www.w3.org/ns/org# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio#" typeof="schema:CreativeWork sioc:Post prov:Entity">
        <main>
            <article about="" typeof="schema:ScholarlyArticle">
                <h1 property="schema:name">On a Web of Data Streams</h1>

                <div id="authors">
                    <dl id="author-name">
                        <dt>Authors</dt>
                        <dd id="author-1"><span about="http://dellaglio.org" rel="schema:creator schema:publisher schema:contributor schema:author"><a about="#daniele" typeof="schema:Person" rel="schema:url" property="schema:name" href="http://dellaglio.org">Daniele Dell'Aglio</a></span><span about="#daniele" rel="schema:memberOf" resource="#UZH"></span><sup><a href="#author-org-1">1</a></sup><sup><a href="#author-email-a">a</a></sup></dd>
                        <dd id="author-2"><span about="" rel="schema:contributor"><a about="#Ralf-Gerstner" typeof="schema:Person" rel="schema:url" property="schema:name" href="http://www.springer.com/">Ralf Gerstner</a></span><span about="#Ralf-Gerstner" rel="schema:memberOf" resource="#Springer-Verlag-Computer-Science-Editorial"></span><sup><a href="#author-org-1">1</a></sup><sup><a href="#author-email-b">b</a></sup></dd>
                        <dd id="author-3"><span about="" rel="schema:contributor"><a about="#Anna-Kramer" typeof="schema:Person" rel="schema:url" property="schema:name" href="http://www.springer.com/">Anna Kramer</a></span><span about="#Anna-Kramer" rel="schema:memberOf" resource="#Springer-Verlag-Computer-Science-Editorial"></span><sup><a href="#author-org-1">1</a></sup><sup><a href="#author-email-c">c</a></sup></dd>
                        <dd id="author-4"><span about="" rel="schema:contributor"><a about="#Frank-Holzwarth" typeof="schema:Person" rel="schema:url" property="schema:name" href="http://www.springer.com/">Frank Holzwarth</a></span><span about="#Frank-Holzwarth" rel="schema:memberOf" resource="#Springer-Verlag-Technical-Support"></span><sup><a href="#author-org-1">1</a></sup><sup><a href="#author-email-d">d</a></sup></dd>
                    </dl>

                    <ul id="author-org">
                        <li id="author-org-1"><sup>1</sup><a about="#UZH" typeof="schema:Organization" property="schema:name" rel="schema:url" href="http://uzh.ch">University of Zurich</a>, <span class="adr"><span class="region">Zurich</span>, <span class="country-name">Switzerland</span></span></li>
                        <li id="author-org-1"><sup>1</sup><a about="#Springer-Verlag-Computer-Science-Editorial" typeof="schema:Organization" property="schema:name" rel="schema:url" href="http://www.springer.com/de/">Springer-Verlag, Computer Science Editorial</a>, <span class="adr"><span class="region">Heidelberg</span>, <span class="country-name">Germany</span></span></li>
                        <li id="author-org-1"><sup>1</sup><a about="#Springer-Verlag-Computer-Science-Editorial" typeof="schema:Organization" property="schema:name" rel="schema:url" href="http://www.springer.com/de/">Springer-Verlag, Computer Science Editorial</a>, <span class="adr"><span class="region">Heidelberg</span>, <span class="country-name">Germany</span></span></li>
                        <li id="author-org-2"><sup>2</sup><a about="#Springer-Verlag-Technical-Support" typeof="schema:Organization" property="schema:name" rel="schema:url" href="http://www.springer.com/de/">Springer-Verlag, Technical Support</a>, <span class="adr"><span class="region">Heidelberg</span>, <span class="country-name">Germany</span></span></li>
                    </ul>

                    <ul id="author-email">
                        <li id="author-email-a"><sup>a</sup><a about="#daniele" rel="schema:email" href="mailto:dellaglio@ifi.uzh.ch">dellaglio@ifi.uzh.ch</a></li>
                        <li id="author-email-b"><sup>b</sup><a about="#Ralf-Gerstner" rel="schema:email" href="mailto:ralf.gerstner@springer.com">ralf.gerstner@springer.com</a></li>
                        <li id="author-email-c"><sup>c</sup><a about="#Anna-Kramer" rel="schema:email" href="mailto:anna.kramer@springer.com">anna.kramer@springer.com</a></li>
                        <li id="author-email-d"><sup>d</sup><a about="#Frank-Holzwarth" rel="schema:email" href="mailto:frank.holzwarth@springer.com">frank.holzwarth@springer.com</a></li>
                    </ul>
                </div>

                <div id="content">
                    <section id="abstract">
                        <h2>Abstract</h2>
                        <div datatype="rdf:HTML" property="schema:abstract">
                          <p>
                            With the growing popularity of IoT and sensor technologies an enormous amount of data is being produced at a very rapid pace.
                            Sensor data mostly consists of live data streams containing sensor observations.
                            These data streams are generated in a distributed fashion by multiple heterogeneous infrastructures having minimal or no interoperability.
                            RDF streams emerged as a model to represent data streams, and RDF Stream Processing (RSP) indicates a set of technologies to process such data.
                            Today we can count several successful stories related to RSP research, but we register the fact that in most of the cases the Web dimension is marginal or missing.
                            We register the lack of proper infrastructures to enable the exchange of RDF streams over heterogeneous and differnt types of RDF stream related processors, which features may vary from data generation to querying, from reasoning to visualization.
                            In this article, we define a set of requirements related to the creation of a web of RDF stream processors. We then use such requirements to first analyse the current state of the art, and then to build a novel proposal named \rseql.
                            <!--support the mitigation of heterogeneity, increasing interoperability and facilitating cross-domain stream querying and reasoning.
                            While existing RSP engines are capable of processing distributed RDF streams, there is still a big roam to improve the ability of existing RSP engines to federate queries over large-scale and highly distributed data streams over the Web.
                            \jpc{from this sentence, it seems that the main issue we want to address is federation}
                          </p>

                          <p>
                            In this paper, we present a federated RSP engine which can execute complex distributed queries over large-scale data streams on the Web.
                            \jpc{is this really what we have? To get to this point we would first need a federated rsp language}
                            Our federated RSP engine is capable of consuming distributed RDF streams using multiple communication protocols to access live data streams.
                            We introduce a uniform stream descriptor for RDF streams publication over the Web.
                            Federated RSP engine is capable of consuming data streams over the Web including the streams generated as an outcome of queries deployed over existing RSP engines.
                            We tested our federated query engine over a real complex scenario of traffic and parking management using datasets collected from infrastructure deployed in the City of Aarhus, Denmark.\footnote{\url{http://iot.ee.surrey.ac.uk:8080/datasets.html}}</p>-->
                        </div>
                    </section>

                    <section id="keywords">
                        <h2>Keywords</h2>
                        <div>
                            <ul>
                                <li>We would like to encourage you to list your keywords here. They should be separated by middots.</li>
                            </ul>
                        </div>
                    </section>

                    <section id="introduction" rel="schema:hasPart" resource="#introduction">
                        <h2 property="schema:name">Introduction</h2>
                        <div datatype="rdf:HTML" property="schema:description">
                          <p>
                            The Web of Data (WoD) vision consists of Web as a distributed database: a vast&mdash;endless&mdash;amount of datasets to be accessed and queried.
                            The Linking Open Data (LOD) cloud is one of the most successful examples of such a vision: more than a thousand of datasets, owned and managed by different organizations, exposing interconnected data to be freely accessed.
                            The data can be accesses in different ways. The two most popular solutions are dereferentiation and through SPARQL endpoints. The idea behind the former is to provide
                            These accesses usually happens through SPARQL, which is both a query language for the RDF data exposed in the LOD \cite{harris_sparql_2013} and a protocol to exchange such data through Internet \cite{feigenbaum_sparql_2013}.\jpc{Not sure SPARQL is the main way of reusing LOD. Sometimes people just dereference links}
                            Since the late 2000s, we have observed a trend that substantially increased the velocity of part of such data.
                            The Internet of Things (IoT) well exemplifies this: sensors create \emph{streams}, i.e., continuous sequences of data generated at very high frequencies. \jpc{velocity is a key factor, but recency is also important}
                            It was therefore normal to ask if the existent WoD solutions were good enough to cope with such data.
                            Looking at the research in database, it is possible to observe that the typical database approaches show several limits while coping with data streams.
                            Stonebraker et al. \cite{stonebraker_8_2005} explained which are the requirements of processing streams, and highlighted the limits of the DBMS approach, e.g., their passive processing models badly works with data with extreme velocity; SQL does not support operators to cope with streams; and it is challenging to predict the behaviour of such systems while coping with streaming data.
                            It is easy to observe that these limits affect SPARQL\jpc{not only sparql but in general the RDF model as underlying representation infrastructure IMO} and existent WoD solutions.
                          </p>

                          <p>
                            As a possible solution, Stream Processing Engines (SPEs) emerged in the data management research to cope with streaming data.
                            They introduce new paradigms and processing models that fit better the requirements of scenarios involving data streams.
                            As a result, a new set of languages have been designed and developed, such as CQL, StreamSQL, EPL, with engines and systems designed with the specific task of processing streams.
                          </p>

                          <p>
                            In the Web of Data, these novel paradigms inspired RDF Stream Processing (RSP): it builds on top of SPEs to mitigate the data heterogeneity issues by exploiting semantic web technologies.
                            As the name suggests, such systems are designed process data streams modelled through RDF, and they offer a wide set of operators, from typical SPE operations (e.g., filters, aggregations, event pattern matching) to reasoning processes.
                          </p>

                          <table id="tab:overview">
                              <caption>Comparison between data management and web of data paradigms</caption>
                              <thead>
                                  <tr><th></th><th>DB</th><th>SPE</th><th>WoD</th><th>WoDS</th></tr>
                              </thead>
                              <tbody>
                                  <tr><td>Processing</td><td>SQL</td><td>StreamSQL (et al.)</td><td>SPAR<b>QL</b></td><td>RSP-QL (et al.)</td></tr>
                                  <tr><td>Data exchange</td><td>-</td><td>-</td><td>HTTP, S<b>P</b>ARQL</td><td>?</td></tr>
                              </tbody>
                          </table>

                          <p>
                            RSP fills an important gap between the Web of Data towards a Web of Data Streams (WoDS): it introduces processing models and languages to process streams on the Web, mostly of them captured by reference models as RSEP-QL and LARS.
                            However, an important elements is still missing, and it is a technical infrastructure to manage data exchange.
                            As depicted in Table <a href="#tab:overview">1</a>, data can be exchanged by HTTP (following the linked data principles) or via the SPARQL protocol.
                            These solutions perfectly suit the cases where engines follow passive processing models, i.e., they pull the data when needed, but not when engines adopt passive processing models.
                          </p>

                          <p>
                            In this paper, we ask <em>what is the best data exchange infrastructure to perform stream processing on the Web?</em> \dd{what is a ( suitable [or] proper ) data exchange infrastructure to perform stream processing on the Web?}\jpc{tricky: is it only an infrastructure what we propose? }
                            In other words, we ask ourselves how can we build an infrastructure that enables the scenario in Figure <a href="#fig:overview">1</a>: a network of RSP engines, distributed on the Web, able to exchange and process RDF streams among them.
                          </p>

                          <figure id="fig:overview">
                              <object data="img/overview.png"  type="image/png" width="200"></object>
                              <figcaption>Overview</figcaption>
                          </figure>

                          <p>
                            The solution should take into account both the nature of the engines and the Web setting.
                            We should indeed consider that existing RSP engines are heterogeneous in terms of operators and APIs to control them, as well as the nature of the Web, that is distributed and relies on existing technologies and standards.
                            We envision a scenario as the one depicted in Figure <a href="#fig:overview">1</a>: interconnected RSPs that perform several tasks such as querying to reasoning, exchanging the results and producing sophisticated analyses.
                          </p>

                          <p>
                            In the following we present \rsep, a framework to build complex network of RSP engines on the Web. \rsep brings a communication protocol to initialize the connection between two RSP engines and to manage the data exchange.
                            This is implemented through two interfaces for the elements that produce and consume streams, and a vocabulary to annotate a stream.
                            We design and build \rsep taking into account existing previous results such as the W3C RSP-CG reports \cite{}, existing RSP engines, protocol and standards.
                            We empirically show that \rsep enables the construction of a Web of Data Streams by evaluating the introduced overhead and making a study about scalability.
                          </p>

                          <p>
                            The paper is structured as follows.
                            We set requirements for communication of Web stream processors in Section <a href="#reqs">2</a>.
                            In Section <a href="#related-work">3</a>, we review the state of the art and we discuss the solutions available so far.
                            Section <a href="#rsep">6</a> presents \rsep, describing its components and presenting some existing implementation.
                            We evaluate \rsep in Section <a href="#impl">5</a> before concluding with remarks and future directions in Section <a href="#concl">6</a>.
                          </p>
                        </div>
                    </section>

                    <section id="reqs" rel="schema:hasPart" resource="#reqs">
                      <h2 property="schema:name">Requirements</h2>
                      <div datatype="rdf:HTML" property="schema:description">
                        <p>
                          To design an infrastructure to exchange RDF streams on the Web, we first define a set of requirements.
                          As we will see, three of them are extensions of Stonebraker et al.'s rules for SPE \cite{stonebraker_8_2005}, while others are elicited from real-world <a href="https://www.w3.org/community/rsp/wiki/Use_cases">use
                          cases</a>.
                        </p>

                        <section id="sec:scenario-req-1">
                          <h4 property="schema:name">R1: Keep the data moving</h4>
                          <div datatype="rdf:HTML" property="schema:description">
                            <p>
                              The first rule of \cite{stonebraker_8_2005} states that a SPE "should use an	active (i.e., non-polling) processing model".
                              Looking at the WoD, we can notice that most of the interactions follow a polling paradigm and are stateless.
                              This is a direct consequence of the client-server paradigm at the basis of HTTP and the Web: servers supplying resources to client on demand.
                              In this sense, the WoD is not the most suitable environment to perform stream	processing.
                              Therefore, as first requirement, <em>\rsep must prioritize active paradigms for data stream exchange, where the	data supplier can <em>push</em> the stream content to the actors interested in it</em>.
                            </p>
                          </div>
                        </section>

                        <section id="sec:scenario-req-2">
                          <h4 property="schema:name">R2: Stored and streamed data</h4>
                          <div datatype="rdf:HTML" property="schema:description">
                            <p>
                              The fifth rule of 	\cite{stonebraker_8_2005} is about the "capability to efficiently store, access and modify state information, and combine it with live streaming data".
                              We need to revisit this rule by a WoD point of view, in particular about the notion of stored data.
                              In our context, this data is represented by any dataset that is exposed to the Web through SPARQL endpoints or through Linked Data technologies.
                              Our second requirement states that <em>\rsep must enable the combination of streaming and stored data</em>.
                              In this case combination has a broad meaning, and may refer to several operations, such as stream enrichment, stream storage or fact derivation.
                            </p>
                          </div>
                        </section>

                        <section id="sec:scenario-req-3">
                          <h4 property="schema:name">R3: High availability, distribution and scalability</h4>
                          <div datatype="rdf:HTML" property="schema:description">
                            <p>
                              The sixth rule of \cite{stonebraker_8_2005} states that  "ensure that the applications are up and available, and the integrity of the data maitained at all times, despite failures",
                              while the seventh states that SPE  "must be able to distribute its processing across multiple processors and machines to achieve incremental scalability. Ideally, the distribution should be automatic and transparent".
                            	Even if such rules are mainly related to the stream processing engines architecture, we can infer some useful indication for the design of \rsep.
                              Our third requirement is that <em>\rsep must enable the possibility to build reliable, distributed and scalable streaming applications</em>.
                            </p>
                          </div>
                        </section>

                        <section id="sec:scenario-req-4">
                          <h4 property="schema:name">R4: Operations on the stream content</h4>
                          <div datatype="rdf:HTML" property="schema:description">
                            <p>
                              Every use case has special requirements on the way the streaming data should processed.
                              Querying is an option when the goal is to aggregate, filter and look of relevant pattern of events.
                              However, other alternatives are possible, such as deductive, inductive and other types of reasoning; stream generation and visualization.
                            	<em>\rsep must guarantee a wide range of operations over the stream</em>.
                              Such a requirement is important, in particular on the Web perspective, where data may be accessed and used in unexpected ways by third-part entities.
                              \jpc{wide range of operations: is it too vague?}
                            </p>
                          </div>
                        </section>

                        <section id="sec:scenario-req-5">
                          <h4 property="schema:name">R5: Accessible information about the stream</h4>
                          <div datatype="rdf:HTML" property="schema:description">
                            <p>
                              While the nature of the stream content is highly dynamic and volatile, the stream itself is a resource that can be described.
                              Such descriptions are needed in a number of cases.
                              For example, statistics about the frequency and the size of the stream content may be used to enable query optimization in the RSP engines; information about the generation of the stream may be used to enable provenance-related reasoning; description of the features of the streams may be collected in registries to achieve search and discovery.
                              Our fifth requirement states that <em>\rsep must support the publication of stream descriptions</em>.
                          </div>
                        </section>

                        <section id="sec:scenario-req-6">
                          <h4 property="schema:name">R6: Stream variety support</h4>
                          <div datatype="rdf:HTML" property="schema:description">
                            <p>
                              The decentralized and bottom-up nature of the Web make hard&mdash;if not impossible&mdash;to define \emph{the} model and serialization format for streams.
                            	Looking at the use cases in the RSP-CG wiki, it is easy to observe that: streams can have different velocities (e.g., one new item every minute vs every millisecond); time annotations can be composed by zero, one, two or more time instants, item schemata can be simple (e.g., numbers) or complex (e.g., graphs or tables).
                              To preserve the heterogeneity that characterize the Web, <em>\rsep should support the exchange of a wide variety of streams</em>.
                          </div>
                        </section>

                        <section id="sec:scenario-req-7">
                          <h4 property="schema:name">R7: Reuse of technologies and standards</h4>
                          <div datatype="rdf:HTML" property="schema:description">
                            <p>
                              A common problem when building new frameworks and infrastructures is to find a good trade-off among what is new and what exists.
                              On the one hand, creating everything from scratch is an opportunity to create a solution that perfectly fits the requirements, but on the other hand adopting existing specifications (i.e., standards and protocols) allows reusing existing tools and methods.
                              This is particular true on the Web, where guaranteeing compatibility is mandatory in order to enable interoperability.
                              Our last requirements states that the design of <em>\rsep should exploit as much as possible existing protocols and standards</em>.
                            </p>
                          </div>
                        </section>
                      </div>
                    </section>

                    <section id="related-work" rel="schema:hasPart" resource="#related-work">
                      <h2 property="schema:name">Related Work</h2>
                    </section>

                    <section id="rsep" rel="schema:hasPart" resource="#rsep">
                      <h2 property="schema:name">A framework to exchange RDF streams on the Web</h2>
                      <div datatype="rdf:HTML" property="schema:description">
                          <section id="rdf-stream" rel="schema:hasPart" resource="#rdf-stream">
                            <h3 property="schema:name">RDF stream: model and serialization</h3>
                            <div datatype="rdf:HTML" property="schema:description">
                              <p>
                                Following the requirements and the type of scenarios that we address in this work, we need to represent heterogeneous data streams, which can be shared by different processing engines, and whose data can be not only retrievable but interpretable and distributable among these engines.
                                The RDF model lends itself as a natural candidate for representing different types of data, thanks to its flexibility in data modeling, and the usage of well established standards, designed for the Web.
                                However, in order to be used in a streaming scenario, the RDF model needs extensions, as shown in previous works \cite{lephuoc2011native,barbieri_c-sparql:_2010}.
                              </p>

                              <p>
                                We can distinguish two kinds of data in the requirements, first the streaming data, which are by nature highly dynamic and labeled with time annotations.
                                Second, the contextual or background data, which changes lees often, provides information that enriches the streaming data (e.g. including location, profiles, producer data, system descriptions, etc.).
                                For the latter, RDF graphs can be used as an underlying data model, while streams can be captured using an extended RDF stream data model.
                              </p>

                              <p>
                                To fulfill these goals, we adopt the notion of time-annotated RDF graphs as elements of RDF streams, following the data model under design by the <a href="https://www.w3.org/community/rsp/">W3C RSP Community Group</a> (RSP CG).
                              </p>

                              <p>
                                We define a \emph{timeline}~$T$ as an infinite, ordered
                                sequence of time entities $(t_1, t_2,\ldots)$, where~$t_i{\in}\mbox{TimeEntities}$
                                and for all~$i{>}0$, it holds that~$t_{i}$ happened before $t_{i+1}$. When the time entities are restricted to instants, $t_{i+1}-t_i$ is a constant, i.e. the \emph{time unit} of~$T$.
                              </p>

                              <p>
                                Following the definitions in \cite{dellaglio2016}, the definition of RDF streams can be formulated as an extension of RDF Graphs with time annotations.
                              </p>

                                \parsec{RDF Stream}
                              <p>
                                  A \emph{timestamped RDF graph} is a pair~$(G, t)$, where $G$ is an RDF
                                  graph and $t\in T$ is a time entity.  An \emph{RDF stream}~$S$ is a (potentially) unbounded sequence of timestamped RDF graphs in a non-decreasing time order:

                                  <figure class="equation" typeof="doco:FormulaBox">
                                      <math xmlns="http://www.w3.org/1998/Math/MathML">
                                          <mi>S</mi><mo>=</mo>
                                          <mo>(</mo><msub><mi>G</mi><mn>1</mn></msub><mo>,</mo><msub><mi>t</mi><mn>1</mn></msub><mo>)</mo><mo>,</mo>
                                          <mo>(</mo><msub><mi>G</mi><mn>2</mn></msub><mo>,</mo><msub><mi>t</mi><mn>2</mn></msub><mo>)</mo><mo>,</mo>
                                          <mo>(</mo><msub><mi>G</mi><mn>3</mn></msub><mo>,</mo><msub><mi>t</mi><mn>3</mn></msub><mo>)</mo><mo>,</mo>
                                          <mo>(</mo><msub><mi>G</mi><mn>4</mn></msub><mo>,</mo><msub><mi>t</mi><mn>4</mn></msub><mo>)</mo><mo>,</mo>
                                          <mo>&#x2026;</mo>
                                      </math>
                                  </figure>
                                  where, for every
                                  <math xmlns="http://www.w3.org/1998/Math/MathML"><mi>i</mi><mo>&gt;</mo><mn>0</mn></math>,
                                  <math xmlns="http://www.w3.org/1998/Math/MathML"><mo>(</mo><msub><mi>G</mi><mi>i</mi></msub><mo>,</mo><msub><mi>t</mi><mi>i</mi></msub><mo>)</mo></math>
                                  is a timestamped RDF graph and
                                  <math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>t</mi><mi>i</mi></msub><mo>&#x2264;</mo><msub><mi>t</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub></math>.
                              </p>

                              <p>
                                In this work, we focus on the model where the time annotation is
                                represented by one time instant, as it is a usual case that appears in relevant scenarios.

                                \begin{example}\label{ex:stream}
                                  $S{=}(G_1,2),(G_2,4),(G_3,6),(G_4,8),(G_5,10),\ldots$,
                                  where each~$G_i$ contains the depicted RDF triples.
                                \end{example}

                                <figure class="listing">
                                    <pre>
<code>{"http://www.w3.org/ns/prov#generatedAtTime": "2015-06-30T16:44:59.587Z",</code>
<code> "@id": "http://streamreasoning.org/TripleWave/ak10992887",</code>
<code> "@graph": [</code>
<code>  { "@id": "http://streamreasoning.org/TripleWavee/ak10992887",</code>
<code>    "@type": "cbench:TrafficObservation",</code>
<code>    "ssn:observedProperty": "cbench:TrafficData",</code>
<code>    "ssn:hasValue": "32",</code>
<code>    "ssn:observedBy": "ins-event:AarhusTrafficData158505"</code>
<code>  }],</code>
<code> "@context": {</code>
<code>    "ssn": "http://www.w3.org/2002/12/cal/ical#",</code>
<code>    "cbench": "http://www.w3.org/2001/XMLSchema#",</code>
<code>    "ins-event": "http://www.insight-centre.org/dataset/SampleEventService#"</code>
<code>}</code>
                                    </pre>
                                    <figcaption>[Example of a computer program from Jensen K., Wirth N.: Pascal User Manual and Report. Springer, New York (1991)]</figcaption>
                                </figure>

                              </p>
                            </div>
                          </section>

                          <section id="protocol" rel="schema:hasPart" resource="#protocol">
                              <h3 property="schema:name">Communication protocol</h4>
                              <div datatype="rdf:HTML" property="schema:description">
                                  <p>
                                    We identify two interfaces, namely <em>producer</em> and <em>consumer</em>.
                                    As the names suggest, the former is implemented by actors that distribute streams across the Web, while the latter is implemented actors who wants to receive streams.
                                  </p>

                                  <p>
                                    Every actor involved in the processing may implement either interface, as well as both of them. This lead us to the following nomenclature.
                                    A <em>stream source</em> implements the producer interface only. Services exposing sensors data on the Web and TripleWave are examples of stream sources.
                                    Similarly, a <em>stream sink</em> implements the consumer interface only, e.g. a dashboard visualising information for the final user.
                                    Finally, a <em>stream transformer</em> implements both the interfaces: it gets as input a stream and outputs another stream, e.g. a stream processor or a stream reasoner.
                                  </p>

                                  <p>
                                    The principal responsibility of the producers is to make streaming data accessible. It is done by exposing <em>Stream Descriptors</em>, i.e. metadata about the streams.
                                    Examples of Stream Descriptor contents are the creator, the adopted vocabulary and statistical information about the stream.
                                    However, the most relevant data the Stream Descriptor brings is about how to effectively access the stream content.
                                    We detail the stream descriptor in Section~\ref{sec:impl:sd}; in the following, we describe how the producer/consumer communication develops.
                                  </p>

                                  <figure id="fig:protocol">
                                      <object data="img/consume.png"  type="image/png" width="200"></object>
                                      <figcaption>Protocol to establish the communication between the producer
                                  			and the consumer interfaces</figcaption>
                                  </figure>

                                  <p>
                                    The communication relies on two phases, depicted in Figure~\ref{fig:protocol}, and it starts on the consumer side.
                                    The consumer only needs to be aware of the IRI of the Stream Descriptor, e.g. consumer user provides it as instruction.
                                    This is what is needed for the first phase, where the consumer accesses the Stream Descriptor IRI (the blue part in Figure~\ref{fig:protocol}) through a HTTP request, following the Linked Data principles.
                                  </p>

                                  <p>
                                    In the second phase, the consumer starts to receive the stream (the light blue part in Figure~\ref{fig:protocol}).
                                    The Service Descriptor brings information about how to access the effective stream content.
                                    That means it describes one or more ways to establish the connection between the consumer and the endpoint that is providing the stream content.
                                    This connection can happen with different protocols, based on push mechanisms. e.g. WebSocket and MQTT, as well as based on pull mechanisms, e.g. HTTP.
                                    Among the several options offered by the producer through the Service Descriptor, consumers chose the way they prefer.
                                    After the decision, consumer can start to receive the stream content and to process it.
                                  </p>

                                  <p>
                                    The choice to allow several channels to distribute the streams gives the freedom to adopt several channels to exchange the streams, relying on different technologies based on requirements in the scenario.
                                  </p>
                              </div>
                          </section>

                          <section id="service-descriptor" rel="schema:hasPart" resource="#service-descriptor">
                              <h3 property="schema:name">Service Descriptor</h3>
                              <div datatype="rdf:HTML" property="schema:description">
                                <p>
                                  The Stream Descriptor is an RDF document providing metadata of the RDF stream that is used by a \emph{consumer} for bootstrapping its stream consuming process.
                                  Realizing that RDF Stream is also an RDF dataset, we extend <a  href="https://www.w3.org/TR/vocab-dcat/">DCAT vocabulary</a> to represent the an RDF Stream as illustrated in Figure~\ref{fig:schema}.
                                  The class RDFStream extends dcat:DataSet to inherit all properties of a RDF dataset, and it also has the properties specific to a stream such as \emph{streamrate} and \emph{streamTemplate}.
                                  The \emph{streamTemplate} property can be used to point to a document that specify the template or the constraint of the RDF stream, for instance, the template can be a RDF document driven <a href="https://www.w3.org/TR/shacl/">SCHACL</a>.
                                  The template can be used as a hint of the data shape of the RDF stream for the consumer to optimize its processing.
                                  It also plays the role as a validation rule for consumer to verify if the incoming data is conformed with the template.
                                </p>

                                <figure id="fig:schema">
                                    <object data="img/streamschema.png"  type="image/png" width="200"></object>
                                    <figcaption>Description of RDF Stream</figcaption>
                                </figure>

                                <figure class="listing">
                                    <pre>
<code>{"@context": {</code>
<code>  "sld": "http://streamreasoning.org/ontologies/wsd#",</code>
<code>  "generatedAt": { </code>
<code>   "@id": "http://www.w3.org/ns/prov#generatedAtTime",</code>
<code>   "@type": "http://www.w3.org/2001/XMLSchema#dateTime" </code>
<code>  }</code>
<code> },</code>
<code> "@type": "wsd:RDFStream",</code>
<code> "dcat:accessURL": "ws://localhost:8101/TripleWave/replay",</code>
<code> "wsd:streamTemplate": {"@id":"http://purl.oclc.org/NET/ssnx/ssn"},</code>
<code> "wsd:shacl": {</code>
<code>  "@list": [</code>
<code>   { "generatedAt": "2016-04-21T13:01:18.663Z", "@id": "tr:1461243678663" },</code>
<code>   { "generatedAt": "2016-04-21T13:01:19.784Z", "@id": "tr:1461243679784" }</code>
<code>  ]</code>
<code> },</code>
<code> "sld:lastUpdated": "2016-04-21T13:02:06.575Z"</code>
<code>}</code>
                                    </pre>
                                    <figcaption>The Stream Descriptor pointing to the iGraph described in Listing~\ref{list:datastreamjson}.</figcaption>
                                </figure>

                                <p>
                                  Note that an RDF can be distributed via different stream channels using different protocols like MQTT and Websocket.
                                  Therefore, a stream channel is an instance of the RDFStreamPublisher class which is linked to the RDFStream class via the property \emph{dcat:distribution}.
                                  The RDFStreamPublisher is used to specify the protocol and the URL whereby the consumer can tap into to receive the stream.
                                  Also, RDFStreamPublisher is a subclass of the dcat:Distribution class which has several properties for the consumer to configure its parsers such as \emph{dcat:mediaType} and {dcat:format}.
                                  An RDFStreamPublisher might provide a continuous query service which is specified by the RSPService class extended from the sd:Service defined by <a href="https://www.w3.org/TR/sparql11-service-description/">SPARQL 1.1 Service description</a>.
                                  As most of RSP engines extend SPARQL 1.1 for their query languages, using the federated service vocabularies will provide useful vocabularies for describing RDF continuous querying services powered by RSP engines such as C-SPARQL and CQELS.
                                </p>
                              </div>
                          </section>
                    </section>

                    <section id="impl" rel="schema:hasPart" resource="#impl">
                        <h2 property="schema:name">Implementation and examples</h2>
                        <div datatype="rdf:HTML" property="schema:description">
                          <section id="impl" rel="schema:hasPart" resource="#impl">
                              <h3 property="schema:name">Stream source example: TripleWave</h3>
                              <div datatype="rdf:HTML" property="schema:description">
                                <p>
                                  TripleWave~\cite{mauri_triplewave:_2016} is a framework to create and expose RDF streams according to the producer interface described above.
                                  Triplewave can be fed with different input, such as non-RDF Web streams or RDF data containing some temporal annotation.
                                </p>

                                <p>
                                  In the former case, TripleWave lifts existing Web streams in RDF streams, such as the <a href="https://en.wikipedia.org/wiki/Special:RecentChanges">Wikipedia update stream</a> and <a href="https://dev.twitter.com/streaming/overview">Twitter stream</a>.
                                  The operation is enabled through R2RML transformations~\cite{das_r2rml:_2012}, that map relational to RDF data.
                                  The lifting operation enables the interoperability among the WSP actors, addressing \dd{Rx}.
                                </p>

                                <p>
                                  In the latter case, TripleWave streams out data stored in a repository.
                                  This mode is useful for benchmarking as well as experimental runs, where data has to be streamed multiple times across the overall network.
                                  Precondition to this mode is the existence of time information associated to the repository content: TripleWave uses them to compute the correct intervals between consecutive events and set delays accordingly.
                                </p>

                                <p>
                                  TripleWave has been designed and implemented to natively implement the producer interface. It exposes the Service Descriptor on an HTTP address, and publishes the streaming data through MQTT and WebSocket.
                                </p>
                              </div>
                          </section>

                          <section id="impl" rel="schema:hasPart" resource="#impl">
                              <h3 property="schema:name">Stream transformer example: C-SPARQL and CQELS</h3>
                              <div datatype="rdf:HTML" property="schema:description">
                                <p>
                                  It is possible to create WSP actors out of existing stream processors by introducing adapters.
                                  We depict this possibility by presenting the cases of C-SPARQL~\cite{barbieri_c-sparql:_2010} and CQELS~\cite{phuoc_native_2011}, two RDF Stream Processing (RSP) engines, i.e. stream processing engines supporting query languages for graph processing, usually extensions of SPARQL~\cite{harris_sparql_2013}.
                                </p>

                                <p>
                                  These engines offers APIs to manage the communication, i.e. (i) declare RDF streams, (ii) push the stream items into the declared RDF streams, (iii) register the query, (iv) register listeners to obtain query results.
                                  The WSP-RSP adapter should implement the producer and consumer interfaces according to such APIs.
                                </p>

                                <p>
                                  The implementation of the consumer interface in the adapter should enable the connection to a stream source or transformer, according to the protocol described above.
                                  Given the nature of such engines, the control of the engine should happen in a query-driven way.
                                  That means, when a new query is registered, the engine should establish the connections for the streams needed to evaluate the query.
                                  The main problem is related to the discovery of the streams: how to let the engine know where the streams are?
                                  The solution we propose is based on the following consideration: both the languages adopted by the engines (respectively C-SPARQL and CQELS-QL) offer the possibility to declare the stream through a IRI, as shown in Listing~\ref{lst:query1}. \dd{fill with the example}
                                  If such IRI denotes a Stream Descriptor address, engines would have the information they need to establish the connection.
                                </p>

                                <p>
                                  Similarly to the consumption, the stream production is query driven. RSP engines stream out the query results and make it available to other agents (e.g. users, other engines, etc.).
                                  The WSP-RSP adapter implements the producer interface as follows. For each query that is registered in the engine, the adapter performs two actions.
                                  First, it creates a Stream Descriptor and exposes it at an HTTP address.
                                  Second, it registers a listener to manage the answers.
                                  The current implementation provides the listeners for MQTT and WebSocket.
                                  The first forwards the results to an MQTT channel, while the latter sends the result to the adapter, that manages the ongoing connections.
                                  In this way, several actors may access the results of the same query.
                                </p>
                              </div>
                        </section>
                    </section>

                    <section id="concl" rel="schema:hasPart" resource="#concl">
                        <h2 property="schema:name">Conclusions</h2>
                        <div datatype="rdf:HTML" property="schema:description">
                        </div>
                    </section>


                    <section id="references">
                        <h2>References</h2>
                        <div>
                            <ol>
                                <li id="ref-1" property="schema:citation">Smith, T.F., Waterman, M.S.: Identification of Common Molecular Subsequences. J. Mol. Biol. 147, 195197 (1981)</li>
                                <li id="ref-2" property="schema:citation">May, P., Ehrlich, H.C., Steinke, T.: ZIB Structure Prediction Pipeline: Composing a Complex Biological Workflow through Web Services. In: Nagel, W.E., Walter, W.V., Lehner, W. (eds.) Euro-Par 2006. LNCS, vol. 4128, pp. 11481158. Springer, Heidelberg (2006)</li>
                                <li id="ref-3" property="schema:citation">Foster, I., Kesselman, C.: The Grid: Blueprint for a New Computing Infrastructure. Morgan Kaufmann, San Francisco (1999)</li>
                                <li id="ref-4" property="schema:citation">Czajkowski, K., Fitzgerald, S., Foster, I., Kesselman, C.: Grid Information Services for Distributed Resource Sharing. In: 10th IEEE International Symposium on High Performance Distributed Computing, pp. 181184. IEEE Press, New York (2001)</li>
                                <li id="ref-5" property="schema:citation">Foster, I., Kesselman, C., Nick, J., Tuecke, S.: The Physiology of the Grid: an Open Grid Services Architecture for Distributed Systems Integration. Technical report, Global Grid Forum (2002)</li>
                                <li id="ref-6" property="schema:citation">National Center for Biotechnology Information, http://www.ncbi.nlm.nih.gov</li>
                            </ol>
                        </div>
                    </section>
                </div>
            </article>
        </main>
    </body>
</html>
